{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{215:function(t,s,a){t.exports=a.p+\"assets/img/hbase.93edf177.png\"},216:function(t,s,a){t.exports=a.p+\"assets/img/hbase_sql.959a0d0b.png\"},217:function(t,s,a){t.exports=a.p+\"assets/img/hbase_table.1b989bf7.png\"},218:function(t,s,a){t.exports=a.p+\"assets/img/hbase_jz.3ac5b219.png\"},219:function(t,s,a){t.exports=a.p+\"assets/img/hbase_regin.3283b72d.png\"},220:function(t,s,a){t.exports=a.p+\"assets/img/hbase_zk.1a45a579.png\"},221:function(t,s,a){t.exports=a.p+\"assets/img/hbase_scan.d6d8c032.png\"},222:function(t,s,a){t.exports=a.p+\"assets/img/hbase_memory.70808c99.png\"},223:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs_log1.44b22be9.png\"},224:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs_log2.306c9b8c.png\"},225:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs_log3.0acba47d.png\"},226:function(t,s,a){t.exports=a.p+\"assets/img/cdh_hbase.fa0f938d.png\"},227:function(t,s,a){t.exports=a.p+\"assets/img/hbase_table1.21e70f48.png\"},228:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs.a9abf4d8.png\"},229:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs1.3c560501.png\"},230:function(t,s,a){t.exports=a.p+\"assets/img/hbase_hdfs2.99b2c73a.png\"},231:function(t,s,a){t.exports=a.p+\"assets/img/hbase_byte.ff2c0d41.png\"},293:function(t,s,a){\"use strict\";a.r(s);var n=a(28),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[n(\"h1\",{attrs:{id:\"hbase\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hbase\"}},[t._v(\"#\")]),t._v(\" HBase\")]),t._v(\" \"),n(\"p\",[t._v(\"官网：http://hbase.apache.org\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(215),alt:\"\"}})]),t._v(\" \"),n(\"p\",[t._v(\"HDFS：Hadoop分布式文件系统，适合非结构化数据的存储以及读取。\")]),t._v(\" \"),n(\"p\",[t._v(\"Apache HBase建立在HDFS之上的分布式、基于列存储的非关系型数据库；具有可靠、稳定、自动容错、多版本特性。\")]),t._v(\" \"),n(\"p\",[t._v(\"HBase实际上是Google BigTable项目的开源实现，它适合于海量的大规模（数十亿行、数百万列）的结构化数据存储。\")]),t._v(\" \"),n(\"p\",[t._v(\"当需要随机、实时读写访问大数据时,使用HBase。\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_1-概念特性\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-概念特性\"}},[t._v(\"#\")]),t._v(\" 1. 概念特性\")]),t._v(\" \"),n(\"p\",[t._v(\"HBASE是一个\"),n(\"strong\",[t._v(\"数据库\")]),t._v(\"----可以提供数据的实时\"),n(\"strong\",[t._v(\"随机读写\")])]),t._v(\" \"),n(\"p\",[t._v(\"HBASE与mysql、oralce、db2、sqlserver等关系型数据库不同，它是一个NoSQL数据库（非关系型数据库）\")]),t._v(\" \"),n(\"p\",[t._v(\"Hbase的表模型与关系型数据库的表模型不同：\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[t._v(\"Hbase的表没有固定的字段定义\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase的表中每行存储的都是一些key-value对\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase中的数据，包含行键，包含key，包含value，HBase中的数据都是字符串（底层存储采用的是byte[]），没有类型，hbase不负责为用户维护数据类型\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"HBASE对事务的支持很差\")])])]),t._v(\" \"),n(\"p\",[t._v(\"HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"Hbase的表数据存储在HDFS文件系统中\")])]),t._v(\" \"),n(\"p\",[t._v(\"从而，hbase具备如下特性：存储容量可以线性扩展； 数据存储的安全性可靠性极高！\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_2-各种数据库之间的差别比较\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-各种数据库之间的差别比较\"}},[t._v(\"#\")]),t._v(\" 2. 各种数据库之间的差别比较\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(216),alt:\"\"}})]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_2-1-hbase和hive区别\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-1-hbase和hive区别\"}},[t._v(\"#\")]),t._v(\" 2.1 HBase和Hive区别\")]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_2-1-1-hive-数据仓库的理解\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-1-1-hive-数据仓库的理解\"}},[t._v(\"#\")]),t._v(\" 2.1.1 Hive 数据仓库的理解\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"仓库就是存放历史数据存的地方，反复对历史数据进行读操作，统计分析操作，历史数据不需要修改。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hive严格意义上来讲不能算是数据库。\")]),t._v(\" \"),n(\"p\",[t._v(\"Hive与Hbase巨大的区别在于，Hive底层依赖的文件系统HDFS中的数据是用户提交的，没有固定的格式，可以理解成按照分隔符分割的简单文本，而不是精心设计的文件（如Mysql那样精心设计的文件加上mysql中共的软件系统，可以对数据进行随机的访问和修改操作），Hive只能对这些数据进行读取，分析，不能对修改和跟新数据。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"mysql也当然具备做为数据仓库的功能和能力，但是数据量太大是，mysql不适合，mysql适于联机事务处理（在线实时交互）。\")])])]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_2-1-2-hbase\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-1-2-hbase\"}},[t._v(\"#\")]),t._v(\" 2.1.2 HBase\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"同msyql一样，底层的文件系统的精心设计的，Hbase的底层文件系统也是HDFS。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"具有联机事务处理数据库的特性（\"),n(\"strong\",[t._v(\"快速\")]),t._v(\" \"),n(\"strong\",[t._v(\"实时\")]),t._v(\"操作数据库，增删改查）。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Hbase本身的特性：\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[t._v(\"文件系统：HDFS（表可以很大很大）\")]),t._v(\" \"),n(\"li\",[t._v(\"分布式系统\")]),t._v(\" \"),n(\"li\",[t._v(\"nosql表结构\")])])])]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_3-hbase-特性与表结构\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-hbase-特性与表结构\"}},[t._v(\"#\")]),t._v(\" 3. HBase 特性与表结构\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(217),alt:\"Hbase的逻辑结构\"}})]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"列族\")]),t._v(\"：KV分为若干的大类：，如上表所示。\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[t._v(\"每个列族中的kv数据可以随意存放，key可以不同，没有严格要求，完全有用户决定，当然一般使用情况下，数据是规整的；\")])]),t._v(\" \"),n(\"p\",[t._v(\"如：下表是可以的，但是为了数据的规整，一般不建议随意为key起名字，最好保持一致。\")]),t._v(\" \"),n(\"table\",[n(\"thead\",[n(\"tr\",[n(\"th\",[t._v(\"rowkey\")]),t._v(\" \"),n(\"th\",[t._v(\"base_info\")])])]),t._v(\" \"),n(\"tbody\",[n(\"tr\",[n(\"td\",[t._v(\"001\")]),t._v(\" \"),n(\"td\",[t._v(\"name:jj, age:12, sex:mal\")])]),t._v(\" \"),n(\"tr\",[n(\"td\",[t._v(\"002\")]),t._v(\" \"),n(\"td\",[t._v(\"nick:ls, age:15, xb:male\")])])])]),t._v(\" \"),n(\"ol\",{attrs:{start:\"2\"}},[n(\"li\",[n(\"p\",[t._v(\"同一个列祖中的kv的个数也是灵活的，可以省略某些kv\")]),t._v(\" \"),n(\"p\",[t._v(\"**cell：**同一个数据可以保存多个值\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[t._v(\"一个kv就是一个cell\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"一个key可有有多个版本的值\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"时间戳作为版本\")])])])])]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_4-hbase-整体工作机制\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-hbase-整体工作机制\"}},[t._v(\"#\")]),t._v(\" 4. HBase 整体工作机制\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_4-1-工作机制示意图\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-1-工作机制示意图\"}},[t._v(\"#\")]),t._v(\" 4.1 工作机制示意图\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(218),alt:\"\"}})]),t._v(\" \"),n(\"p\",[t._v(\"Hbase集群中有两个角色\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"region server\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"master\")])]),t._v(\" \"),n(\"p\",[t._v(\"region server负责数据的逻辑处理（增删改查），\"),n(\"strong\",[t._v(\"region server对数据的操作是不经过master\")]),t._v(\"。某一个瞬间master挂了，regionserver还是可以正常服务的，但是一定时间之后，万一某一个regionserver挂了，该regionserver负责的任务得不到重新分配，就会出问题。\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_4-2-存储问题（分散存储）\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-2-存储问题（分散存储）\"}},[t._v(\"#\")]),t._v(\" 4.2 存储问题（分散存储）\")]),t._v(\" \"),n(\"p\",[t._v(\"按照region划分范围存储（region目录还细分为列族目录，列族目录下才存放具体的文件）\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_4-3-查询问题（分布式：分任务查询）\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-3-查询问题（分布式：分任务查询）\"}},[t._v(\"#\")]),t._v(\" 4.3 查询问题（分布式：分任务查询）\")]),t._v(\" \"),n(\"p\",[t._v(\"HBase底层文件系统是HDFS，HBase中的表最终也会落地HDFS，那么Hbase的一张表可以很大很大，表中的数据不断的增加增加存储也是可以的，但是怎么查询呢？\")]),t._v(\" \"),n(\"p\",[t._v(\"当请求特别多的时候，一台HBase服务器（region server）是不行的，HBase是一个分布式的系统，当有多个Hbase提供服务的时候，某一次客户端的请求具体由那个服务器来处理呢？\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[t._v(\"当某一台服务器挂了，谁来接替它的工作，如何接替？\")]),t._v(\" \"),n(\"p\",[t._v(\"​\\t**解决：**服务器需要分任务（分布式系统里肯定是要分任务的）\")]),t._v(\" \"),n(\"p\",[t._v(\"​\\t一台服务器，负责Hbase中某个表的某一个部分。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"如何界定部分？\")]),t._v(\" \"),n(\"p\",[t._v(\"​\\t需要\"),n(\"strong\",[t._v(\"划分范围：\"),n(\"strong\",[t._v(\"按照\")]),t._v(\"行健范围\")])])])]),t._v(\" \"),n(\"p\",[t._v(\"这样通过分任务之后就是一个\"),n(\"strong\",[t._v(\"分布式系统。\"),n(\"strong\",[t._v(\"不同的regionServer可以\")]),t._v(\"并行\")]),t._v(\"的去访问hdfs中的数据（表数据）\"),n(\"strong\",[t._v(\"，\"),n(\"strong\",[t._v(\"这样还有一个问题，若某一张表中的所有数据都存在同一个HDFS中的文件中，即使是负责同一张表的不同范围regionserver，大量的并行请求也会同时访问同一个hdfs文件，这会造成性能上的瓶颈，所以表中的数据在HDFS中是按照\")]),t._v(\"region划分范围存储（region目录还细分为列族目录，列族目录下才存放具体的文件）\")]),t._v(\", 这样\"),n(\"strong\",[t._v(\"同一个表的不同region范围的数据落地HDFS中不同的文件中\")]),t._v(\"。否则会造成即是分了任务一个dataNode被频繁的访问。\")]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_4-3-1-客户端读写数据时的路由流程\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-3-1-客户端读写数据时的路由流程\"}},[t._v(\"#\")]),t._v(\" 4.3.1 客户端读写数据时的路由流程\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"问题描述\")]),t._v(\"：客户端怎么知道他要访问的某个region在那一台regionserver上呢？\")]),t._v(\" \"),n(\"p\",[t._v(\"master是不会保存哪些region在哪些regionserver上的，否则就是有状态的节点了，一旦master挂了，regionserver立刻无法提供服务，而事实不是这样。\")]),t._v(\" \"),n(\"p\",[t._v(\"上述信息就是所谓的索引信息，master是不会保存索引信息的，索引信息是保存在系统索引表中的。\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"索引表当然也存在于hdfs中，且只有一个region；\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"谁来负责查询索引表\")])])]),t._v(\" \"),n(\"p\",[t._v(\"下图所示，索引表数据的查询由hdp-02机器上的regionserver负责，那么客户端怎样知道meta数据由hdp-02负责\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(219),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"zookeeper上会记录元数据索引表，有哪一台regionserver负责管理。\")]),t._v(\"　客户单端，每次访问数据之前，先查询zookeeper。\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(220),alt:\"\"}})]),t._v(\" \"),n(\"p\",[t._v(\"下图为Zookeeper节点\"),n(\"strong\",[t._v(\"meta-region-server的信息\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"访问流程：\")])]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"客户端去Zookeeper上查询，负责索引表数据的regionserver；\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"找该台regionserver服务器，查询出客户端要访问的region数据由哪一台regionserver负责；\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"客户端找具体的regionserver要数据.\")])])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"总结：\")])]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"Hbase表中的数据是存放在hdfs中的。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"regionserver只负责逻辑功能，对数据进行增删改查，不存储它负责的region的数据。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"一个regionserver可以负责多个表的多个region。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"region是regionServer管理数据的基本单元。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"客户端查找数据不经过master。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"客观端查找数据一定经过Zookeeper。\")])])]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_4-4-服务器宕机问题（借助zookeeper实现ha）\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-4-服务器宕机问题（借助zookeeper实现ha）\"}},[t._v(\"#\")]),t._v(\" 4.4 服务器宕机问题（借助Zookeeper实现HA）\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"master对regionserver的监管，状态协调\")])]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"所有的状态信息记录在Zookeeper里。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"master\"),n(\"strong\",[t._v(\"负责监管\")]),t._v(\"region server的状态，知道每一个regionserver负责哪些表的哪些region，不负责帮用户查数据，一旦发现某个region server发生故障，会找另外的一台机器来接替该region server负责的region区域。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"master通过Zookeeper来获取regionserver的状态。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"master通过Zookeeper监听region server，maste是没有状态的节点，master存在单点故障的风险；通过主备容灾实现HA机制。\")])])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"master HA\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"状态信息记录在Zookeeper里。\")])]),t._v(\" \"),n(\"p\",[t._v(\"可以在集群中找任意一台机器启动一个备用的master，新启的这个master会处于backup状态\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_4-5-hbase工作机制补充—regionserver数据管理\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-5-hbase工作机制补充—regionserver数据管理\"}},[t._v(\"#\")]),t._v(\" 4.5 Hbase工作机制补充—regionserver数据管理\")]),t._v(\" \"),n(\"p\",[t._v(\"首先在hbase的表中插入一些数据，然后来观察一下hdfs中存的数据，发现hdfs下并没有数据，但是scan明明可以查到数据的，这是怎么回事呢？\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"https://img2018.cnblogs.com/blog/1020536/201810/1020536-20181016094210414-521552116.png\",alt:\"img\"}})]),t._v(\" \"),n(\"p\",[t._v(\"scan可以查到数据。而上图hdfs中却没有数据文件。\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(221),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"其实：此时此刻的数据位于内存中。\")])]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(222),alt:\"\"}})]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_4-5-1-内存缓存热数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-5-1-内存缓存热数据\"}},[t._v(\"#\")]),t._v(\" 4.5.1 内存缓存热数据\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"每个region在内存中都对应分配一块缓存空间，memstore，但是memstore毕竟有限，不会将全部的数据都存入到内存中，还是有很大的数据是存在hdfs中的。当数据量很小的时候没有必要写入到hdfs文件中，这就解释了为什么上述hdfs中没有文件数据。\")]),t._v(\" \"),n(\"p\",[t._v(\"上述用户插入的数据都保存在了内存中，这样速度会比存入hdfs中快很多，但是又不能吧全部数据都存入到内存中，内存中只会保存一些\"),n(\"strong\",[t._v(\"热数据【刚刚被访问过的，刚刚被插入的数据】\")]),t._v(\"。\")]),t._v(\" \"),n(\"p\",[t._v(\"如果有人找regionserver查数据是，regionserver内存中没有该数据，就会去hdfs中查找，找到之后作为热数据，然后缓存在内存中，超过一段时间没有人访问就不是热数据了，就不会继续保存在内存中。\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"数据保存在内存中就有风险，万一没有来的落地hdfs，\"),n(\"strong\",[t._v(\"宕机\")]),t._v(\"了，内存中的数据会丢失，怎么办？\")]),t._v(\" \"),n(\"p\",[t._v(\"解决方案：regionserver一方面在自己内存中写数据，一方面在hdfs中写日志，一旦宕机后，master找来替换机器后，该机器会读取日志信息，还原内存中的数据。\")])])]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(223),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(224),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(225),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"总结：\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"1、热数据存储\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"2、日志记录\")])]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_4-5-2-持久化到hdfs\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-5-2-持久化到hdfs\"}},[t._v(\"#\")]),t._v(\" 4.5.2 持久化到hdfs\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"当内存中的数据插满时候，数据会持久化到hdfs中\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"当hbase退出时候，数据也会持久化到hdfs中\")])])]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_5-安装-hbase\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_5-安装-hbase\"}},[t._v(\"#\")]),t._v(\" 5. 安装 HBase\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"安装hbase\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#安装hbase\"}},[t._v(\"#\")]),t._v(\" 安装HBase\")]),t._v(\" \"),n(\"p\",[t._v(\"HBase是Google Bigtable的开源实现，它利用Hadoop HDFS作为其文件存储系统，利用Hadoop MapReduce来处理HBase中的海量数据，利用Zookeeper作为协同服务。所以安装HBase之前还需要安装zookeeper和hdfs。\")]),t._v(\" \"),n(\"p\",[t._v(\"如果是Apache hadoop就下载相应文件并修改配置文件安装。我用的是cloudera hadoop就直接在集群管理界面添加服务。\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(226),alt:\"\"}})]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_6-hbase-客户端\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-hbase-客户端\"}},[t._v(\"#\")]),t._v(\" 6. HBase 客户端\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"_6-1-命令行客户端\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-命令行客户端\"}},[t._v(\"#\")]),t._v(\" 6.1 命令行客户端\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#bin/hbase shell\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#hbase(main):001:0> list     // 查看表\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#hbase(main):002:0> status   // 查看集群状态\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"#hbase(main):003:0> version  // 查看集群版本\")]),t._v(\"\\n\")])])]),n(\"p\",[t._v(\"进入命令行客户端，help查看都有哪些命令【命令分为不同的组别 ddl dml tools replication...】。\")]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_6-1-1-建表\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-1-建表\"}},[t._v(\"#\")]),t._v(\" 6.1.1 建表\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"create \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'extra_info'\")]),t._v(\"\\n\\t\\t表名      \\t列族名   \\t\\t列族名\\n\")])])]),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":004:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" create \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'extra_info'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1.4210\")]),t._v(\" seconds\\n\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" Hbase::Table - t_user_info\\n\")])])]),n(\"p\",[n(\"strong\",[t._v(\"查看HBase建表后的状态\")])]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(227),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"HDFS中的数据\")])]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(228),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(229),alt:\"\"}})]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(230),alt:\"\"}})]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_6-1-2-插入数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-2-插入数据\"}},[t._v(\"#\")]),t._v(\" 6.1.2 插入数据\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"put命令\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"语法：\")])]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'表名'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'行健'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'列族:key'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'value'\")]),t._v(\"\\n\")])])]),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":004:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:username'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'zhangsan'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.2250\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":005:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:age'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'18'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0180\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":006:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:sex'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'female'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0250\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":007:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'extra_info:career'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'it_java'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0150\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":008:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'002'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:username'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'lisi'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0130\")]),t._v(\" seconds\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-1-3-查询数据方式一：get-单行查询\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-3-查询数据方式一：get-单行查询\"}},[t._v(\"#\")]),t._v(\" 6.1.3 查询数据方式一：get 单行查询\")]),t._v(\" \"),n(\"p\",[t._v(\"语法：\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"-- 返回该行全部数据\\nget \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'表名'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'行健'\")]),t._v(\"\\n\\n-- 返回该行指定列族：key的值\\nget \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'表名'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'行健'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'列族:key'\")]),t._v(\"\\n\")])])]),n(\"p\",[t._v(\"特性：\"),n(\"strong\",[t._v(\"HBase会对 ' 列族：key ' 进行字典序排序\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"timestamp：是key的版本号\")])]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":001:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" get \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\"\\nCOLUMN                       CELL\\n base_info:age               \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464683099\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"18\")]),t._v(\"\\n base_info:sex               \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464711338\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"female\\n base_info:username          \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464658247\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"zhangsan\\n extra_info:career           \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464797473\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"it_java\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"4\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.2740\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":002:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" get \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:username'\")]),t._v(\"\\nCOLUMN                       CELL\\n base_info:username          \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464658247\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"zhangsan\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0260\")]),t._v(\" seconds\\n\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-1-4-查询数据方式二：scan-扫描\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-4-查询数据方式二：scan-扫描\"}},[t._v(\"#\")]),t._v(\" 6.1.4 查询数据方式二：scan 扫描\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"scan是全表扫描\")])]),t._v(\" \"),n(\"p\",[t._v(\"特性：\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"1、先按照行健排序。\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"2、同一行健，按照key的字典序排序。\")])]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":012:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" scan \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\"\\nROW              COLUMN+CELL\\n 001             \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"column\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"base_info:age, \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464683099\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"18\")]),t._v(\"\\n 001             \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"column\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"base_info:sex, \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464711338\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"female\\n 001             \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"column\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"base_info:username, \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464658247\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"zhangsan\\n 001             \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"column\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"extra_info:career, \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464797473\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"it_java\\n 002             \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"column\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"base_info:username, \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"timestamp\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1585464828257\")]),t._v(\", \"),n(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"value\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"lisi\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0190\")]),t._v(\" seconds\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-1-5-delete-删除一个kv数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-5-delete-删除一个kv数据\"}},[t._v(\"#\")]),t._v(\" 6.1.5 delete 删除一个kv数据\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":021:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" delete \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'base_info:sex'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0390\")]),t._v(\" seconds\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-1-6-deleteall-删除整行数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-6-deleteall-删除整行数据\"}},[t._v(\"#\")]),t._v(\" 6.1.6 deleteall 删除整行数据\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":024:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" deleteall \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0090\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":025:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" get \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\",\"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'001'\")]),t._v(\"\\nCOLUMN                            CELL                                                                                            \\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0110\")]),t._v(\" seconds\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-1-7-删除整个表\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-1-7-删除整个表\"}},[t._v(\"#\")]),t._v(\" 6.1.7 删除整个表\")]),t._v(\" \"),n(\"p\",[t._v(\"语法：\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"-- 停用表\\ndisable 表名\\n-- 删除表\\ndrop 表名\\n\")])])]),n(\"p\",[t._v(\"删除表之前先要停用表。\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-shell extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[n(\"code\",[t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":028:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" disable \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2.3640\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":029:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" drop \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'t_user_info'\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1.2950\")]),t._v(\" seconds\\n\\nhbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"main\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\":030:\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[n(\"span\",{pre:!0,attrs:{class:\"token file-descriptor important\"}},[t._v(\"0\")]),t._v(\">\")]),t._v(\" list\\nTABLE                                                                                                                             \\n\"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" row\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"s\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"in\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0.0130\")]),t._v(\" seconds\\n\")])])]),n(\"h3\",{attrs:{id:\"_6-2-客户端api\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-2-客户端api\"}},[t._v(\"#\")]),t._v(\" 6.2 客户端api\")]),t._v(\" \"),n(\"p\",[t._v(\"如何描述一个表？\")]),t._v(\" \"),n(\"p\",[t._v(\"如何创建一个表？\")]),t._v(\" \"),n(\"p\",[t._v(\"删除一个表？\")]),t._v(\" \"),n(\"p\",[t._v(\"修改一个表？\")]),t._v(\" \"),n(\"blockquote\",[n(\"p\",[t._v(\"步骤：\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[t._v(\"构建连接\")]),t._v(\" \"),n(\"li\",[t._v(\"从连接中取到一个表DDL操作工具admin\")]),t._v(\" \"),n(\"li\",[t._v(\"admin.createTable(表描述对象);\")]),t._v(\" \"),n(\"li\",[t._v(\"admin.disableTable(表名);\")]),t._v(\" \"),n(\"li\",[t._v(\"admin.deleteTable(表名);\")]),t._v(\" \"),n(\"li\",[t._v(\"admin.modifyTable(表名，表描述对象)。\")])])]),t._v(\" \"),n(\"h4\",{attrs:{id:\"_6-2-1-创建连接对象\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-2-1-创建连接对象\"}},[t._v(\"#\")]),t._v(\" 6.2.1 创建连接对象\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"conf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HBaseConfiguration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HColumnDescriptor\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HTableDescriptor\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"client\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Admin\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"client\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Connection\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"client\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ConnectionFactory\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"org\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"apache\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hadoop\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hbase\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"regionserver\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"BloomType\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Connection\")]),t._v(\" conn \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Before\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getConn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// new Configuration() 加载的是hadoop的配置文件：core-site.xml hdfs-site.xml，不会加载hbase-site.xml\")]),t._v(\"\\n　　　　 \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 构建一个连接对象\")]),t._v(\"\\n　　　　 \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Hbase提供了HbaseConfiguraton 用来加载hbase-site.xml\")]),t._v(\"\\n　　　　 \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),t._v(\" conf \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HBaseConfiguration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"create\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 会自动加载hbase-site.xml\")]),t._v(\"\\n　　　　 \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 客户端查询数据的路由流程可知：客户端需要先链接 Zookeeper 获取索引表\")]),t._v(\"\\n        conf\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"set\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"hbase.zookeeper.quorum\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"thtf-01:2181,thtf-02:2181,thtf-03:2181\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n　　　　 \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 创建链接对象\")]),t._v(\"\\n        conn \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ConnectionFactory\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"createConnection\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"conf\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"h4\",{attrs:{id:\"_6-2-2-ddl操作\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_6-2-2-ddl操作\"}},[t._v(\"#\")]),t._v(\" 6.2.2 DDL操作\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 获取一个操作指定表的table对象,进行DML操作\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"t_user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])])]),n(\"h5\",{attrs:{id:\"增加数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#增加数据\"}},[t._v(\"#\")]),t._v(\" 增加数据\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"Table对象，进行DML操作;\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"数据封装对象put;\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"Table.put(put) | Table.put(List\"),n(\"put\",[t._v(\"puts);\")])],1)])]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[t._v(\"    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"/**\\n     * 增\\n     * 改:put来覆盖\\n     * @throws Exception \\n     */\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"testPut\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 获取一个操作指定表的table对象,进行DML操作\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"t_user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 构造要插入的数据为一个Put类型(一个put对象只能对应一个rowkey)的对象\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"001\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"username\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"张三\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"18\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"extra_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"addr\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"北京\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),t._v(\" put2 \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"002\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"username\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"李四\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"28\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        put2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"extra_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"addr\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"上海\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \\n\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" puts \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        puts\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        puts\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"put2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 插进去\")]),t._v(\"\\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"puts\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"    \\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[t._v(\"   \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"/**\\n     * 循环插入大量数据\\n     * @throws Exception \\n     */\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"testManyPuts\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" puts \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"100000\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),t._v(\" put \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"\"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"username\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"张三\"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"18\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"extra_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"addr\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"北京\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \\n            puts\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"put\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"puts\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"h5\",{attrs:{id:\"删除数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#删除数据\"}},[t._v(\"#\")]),t._v(\" 删除数据\")]),t._v(\" \"),n(\"p\",[t._v(\"对称结构，插入的时候需要Put对象\")]),t._v(\" \"),n(\"p\",[t._v(\"删除的时候，需要Delete对象\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[t._v(\"    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"/**\\n     * 删\\n     * @throws Exception \\n     */\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"testDelete\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 构造一个对象封装要删除的数据信息　　　　 \")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 全部删除\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Delete\")]),t._v(\" delete1 \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Delete\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"001\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 删除指定的key\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Delete\")]),t._v(\" delete2 \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Delete\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"002\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"　\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// qualifier为用户意义上的key，hbase中 family+qualifier 为一个key\")]),t._v(\"\\n        delete2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addColumn\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"extra_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Bytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"addr\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Delete\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" dels \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dels\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"delete1\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dels\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"delete2\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"delete\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"dels\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"h5\",{attrs:{id:\"修改数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#修改数据\"}},[t._v(\"#\")]),t._v(\" 修改数据\")]),t._v(\" \"),n(\"p\",[t._v(\"使用put来覆盖\")]),t._v(\" \"),n(\"h5\",{attrs:{id:\"查看数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#查看数据\"}},[t._v(\"#\")]),t._v(\" 查看数据\")]),t._v(\" \"),n(\"p\",[t._v(\"qualifier为用户意义上的key，hbase中 family+qualifier 为一个key\")]),t._v(\" \"),n(\"p\",[t._v(\"对称结构，插入的时候需要Put对象\")]),t._v(\" \"),n(\"p\",[t._v(\"删除的时候，需要Delete对象\")]),t._v(\" \"),n(\"p\",[t._v(\"查看单个行键数据，需要Get对象\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"h5\",{attrs:{id:\"取出单行数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#取出单行数据\"}},[t._v(\"#\")]),t._v(\" 取出单行数据\")]),t._v(\" \"),n(\"p\",[t._v(\"Table.get(Get)\")]),t._v(\" \"),n(\"p\",[t._v(\"可以取出该行特定 familyName：key 的 value\")]),t._v(\" \"),n(\"p\",[t._v(\"也可以遍历该行全部的value\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[t._v(\"\\t\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"/**\\n     * 查\\n     * @throws Exception \\n     */\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"testGet\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Get对象 指定行健　\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Get\")]),t._v(\" get \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Get\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"002\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 行健为002的全部数据\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Result\")]),t._v(\" result \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"get\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"get\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 从结果中取用户指定的某个key的value\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" value \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" result\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValue\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"base_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"-------------------------\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 遍历整行结果中的所有kv单元格　　　　 // 类似迭代器\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"CellScanner\")]),t._v(\" cellScanner \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" result\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"cellScanner\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"cellScanner\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"advance\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Cell\")]),t._v(\" cell \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cellScanner\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"current\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" rowArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//本kv所属的行键的字节数组\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" familyArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//列族名的字节数组\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" qualifierArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//列名的字节数据\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" valueArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// value的字节数组\")]),t._v(\"\\n            　　　　　　　\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Hbase不仅仅是存储用户数据，同时还会存储很多附加的信息，以上get方法直接将用户数据和附加数据一起返回，若想获取用户信息，需要指定其实偏移量和数据长度　\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"行键: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"rowArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"列族名: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"familyArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"列名: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"qualifierArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"value: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"valueArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \\n        table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])])]),t._v(\" \"),n(\"li\",[n(\"h5\",{attrs:{id:\"批量取出数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#批量取出数据\"}},[t._v(\"#\")]),t._v(\" 批量取出数据\")]),t._v(\" \"),n(\"p\",[t._v(\"取出多个行健范围的数据，需要Scan对象\")]),t._v(\" \"),n(\"p\",[t._v(\"Table.get(Get)只能取出一个行健范围的数据；\")]),t._v(\" \"),n(\"p\",[t._v(\"如何按照行健范围取出数据？\")]),t._v(\" \"),n(\"p\",[t._v(\"table.getScanner(scan)\")]),t._v(\" \"),n(\"p\",[t._v(\"拿到一个扫描器\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[t._v(\"\\t\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"/**\\n     * 按行键范围查询数据\\n     * @throws Exception \\n     */\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"testScan\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Table\")]),t._v(\" table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" conn\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTable\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TableName\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"valueOf\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"user_info\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v('// Scan scan = new Scan(\"10\".getBytes(), \"10000\".getBytes());')]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 包含起始行键，不包含结束行键,但是如果真的想查询出末尾的那个行键，\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 那么，可以在末尾行键上拼接一个不可见的字节（\\\\000）　　　　 \")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Scan\")]),t._v(\" scan \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Scan\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"10\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"10000\\\\000\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getBytes\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ResultScanner\")]),t._v(\" scanner \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getScanner\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"scan\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Iterator\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Result\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" iterator \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" scanner\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"iterator\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"iterator\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"hasNext\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 拿到一行数据\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Result\")]),t._v(\" result \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" iterator\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"next\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 遍历整行结果中的所有kv单元格\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"CellScanner\")]),t._v(\" cellScanner \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" result\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"cellScanner\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"cellScanner\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"advance\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Cell\")]),t._v(\" cell \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cellScanner\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"current\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" rowArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//本kv所属的行键的字节数组\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" familyArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//列族名的字节数组\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" qualifierArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//列名的字节数据\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"byte\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" valueArray \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueArray\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// value的字节数组\")]),t._v(\"\\n                \\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"行键: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"rowArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getRowLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"列族名: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"familyArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getFamilyLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"列名: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"qualifierArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getQualifierLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"value: \"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"valueArray\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueOffset\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"cell\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getValueLength\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"----------------------\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \\n\")])])])])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"范围查询的细节\")])]),t._v(\" \"),n(\"p\",[t._v(\"道理：在真正的结尾行健后面，拼接一个数字0的字节\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"\\\\000是一个字节，全是0\")])]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"\\\\表示转义，此时后面的0不是数字0，不是字符0\")])]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(231),alt:\"\"}})]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_7-hbase重要特性-排序特性（行键）\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_7-hbase重要特性-排序特性（行键）\"}},[t._v(\"#\")]),t._v(\" 7. Hbase重要特性--排序特性（行键）\")]),t._v(\" \"),n(\"p\",[t._v(\"插入到hbase中去的数据，hbase会自动排序存储：\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"排序规则： 首先看行键，然后看列族名，然后看列（key）名； 按字典顺序\")])]),t._v(\" \"),n(\"p\",[t._v(\"Hbase的这个特性跟查询效率有极大的关系\")]),t._v(\" \"),n(\"p\",[t._v(\"比如：一张用来存储用户信息的表，有名字，户籍，年龄，职业....等信息\")]),t._v(\" \"),n(\"p\",[t._v(\"然后，在业务系统中经常需要：\")]),t._v(\" \"),n(\"p\",[t._v(\"查询某个省的所有用户\")]),t._v(\" \"),n(\"p\",[t._v(\"经常需要查询某个省的指定姓的所有用户\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"思路\")]),t._v(\"：如果能将相同省的用户在hbase的存储文件中连续存储，并且能将相同省中相同姓的用户连续存储，那么，上述两个查询需求的效率就会提高！！！\")]),t._v(\" \"),n(\"p\",[n(\"strong\",[t._v(\"做法\")]),t._v(\"：将查询条件拼到rowkey内\")])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}