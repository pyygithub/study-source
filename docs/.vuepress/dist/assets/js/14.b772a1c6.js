(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{470:function(s,t){s.exports="data:image/png;base64,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"},471:function(s,t,a){s.exports=a.p+"assets/img/sqoop1.c95adefa.png"},472:function(s,t,a){s.exports=a.p+"assets/img/sqoop1.3f5f8231.jpg"},473:function(s,t,a){s.exports=a.p+"assets/img/sqoop2.51aebe6d.jpg"},474:function(s,t,a){s.exports=a.p+"assets/img/cdh_sqoop.ebc8a2ae.png"},521:function(s,t,a){"use strict";a.r(t);var e=a(19),r=Object(e.a)({},(function(){var s=this,t=s.$createElement,e=s._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h1",{attrs:{id:"sqoop"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop"}},[s._v("#")]),s._v(" Sqoop")]),s._v(" "),e("p",[s._v("官网地址： "),e("a",{attrs:{href:"https://links.jianshu.com/go?to=http%3A%2F%2Fsqoop.apache.org%2F",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://sqoop.apache.org/"),e("OutboundLink")],1)]),s._v(" "),e("p",[e("img",{attrs:{src:a(470),alt:""}})]),s._v(" "),e("h2",{attrs:{id:"_1-概述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-概述"}},[s._v("#")]),s._v(" 1. 概述")]),s._v(" "),e("p",[s._v("sqoop是apache旗下一款“Hadoop和关系数据库服务器之间传送数据”的工具。")]),s._v(" "),e("p",[s._v("导入数据：MySQL，Oracle导入数据到Hadoop的HDFS、HIVE、HBASE等数据存储系统；")]),s._v(" "),e("p",[s._v("导出数据：从Hadoop的文件系统中导出数据到关系数据库mysql等 。")]),s._v(" "),e("p",[s._v("Sqoop 的本质还是一个命令行工具，和 HDFS，Hive 相比，并没有什么高深的理论。")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("sqoop：")]),s._v(" "),e("p",[s._v("工具，本质就是迁移数据， 迁移的方式：就是把sqoop的迁移命令转换成MR程序")])]),s._v(" "),e("li",[e("p",[s._v("hive")]),s._v(" "),e("p",[s._v("工具，本质就是执行计算，依赖于HDFS存储数据，把SQL转换成MR程序")]),s._v(" "),e("p",[e("img",{attrs:{src:a(471),alt:""}})])])]),s._v(" "),e("h2",{attrs:{id:"_2-sqoop1-与-sqoop2-架构对比"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-sqoop1-与-sqoop2-架构对比"}},[s._v("#")]),s._v(" 2. Sqoop1 与 Sqoop2 架构对比")]),s._v(" "),e("ul",[e("li",[e("p",[e("strong",[s._v("版本号对比")])]),s._v(" "),e("p",[s._v("两代之间是两个完全不同的版本，不兼容\nsqoop1：1.4.x")]),s._v(" "),e("p",[s._v("sqoop2：1.99.x")])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("sqoop2比sqoop1的改进")])]),s._v(" "),e("p",[s._v("(1) 引入sqoop server，集中化管理connector等\n(2) 多种访问方式：CLI,Web UI，REST API\n(3) 引入基于角色 的安全机制")])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("sqoop2和sqoop1的功能性对比")])]),s._v(" "),e("table",[e("thead",[e("tr",[e("th",[s._v("功能")]),s._v(" "),e("th",[s._v("Sqoop 1")]),s._v(" "),e("th",[s._v("Sqoop 2")])])]),s._v(" "),e("tbody",[e("tr",[e("td",[s._v("用于所有主要 RDBMS 的连接器")]),s._v(" "),e("td",[s._v("支持")]),s._v(" "),e("td",[s._v("不支持"),e("br"),s._v("解决办法： 使用已在以下数据库上执行测试的通用 JDBC 连接器： Microsoft SQL Server 、 PostgreSQL 、 MySQL 和 Oracle 。 "),e("br"),s._v("此连接器应在任何其它符合 JDBC 要求的数据库上运行。但是，性能可能无法与 Sqoop 中的专用连接器相比")])]),s._v(" "),e("tr",[e("td",[s._v("Kerberos 安全集成")]),s._v(" "),e("td",[s._v("支持")]),s._v(" "),e("td",[s._v("不支持")])]),s._v(" "),e("tr",[e("td",[s._v("数据从 RDBMS 传输至 Hive 或 HBase")]),s._v(" "),e("td",[s._v("支持")]),s._v(" "),e("td",[s._v("不支持"),e("br"),s._v("解决办法： 按照此两步方法操作。 将数据从 RDBMS 导入 HDFS 在 Hive 中使用相应的工具和命令（例如 LOAD DATA 语句），手动将数据载入 Hive 或 HBase")])]),s._v(" "),e("tr",[e("td",[s._v("数据从 Hive 或 HBase 传输至 RDBMS")]),s._v(" "),e("td",[s._v("不支持"),e("br"),s._v("解决办法： 按照此两步方法操作。 从 Hive 或 HBase 将数据提取至 HDFS （作为文本或 Avro 文件） 使用 Sqoop 将上一步的输出导出至 RDBMS")]),s._v(" "),e("td",[s._v("不支持"),e("br"),s._v("按照与 Sqoop 1 相同的解决方法操作")])])])])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("sqoop1和sqoop2的架构对比")])]),s._v(" "),e("p",[s._v("sqoop1的架构图")]),s._v(" "),e("p",[e("img",{attrs:{src:a(472),alt:""}})]),s._v(" "),e("p",[s._v("版本号为1.4.x为sqoop1\n在架构上：sqoop1使用sqoop客户端直接提交的方式\n访问方式：CLI控制台方式进行访问\n安全性：命令或脚本中指定用户数据库名及密码")]),s._v(" "),e("p",[s._v("sqoop2的架构图")]),s._v(" "),e("p",[e("img",{attrs:{src:a(473),alt:""}})]),s._v(" "),e("p",[s._v("版本号为1.99x为sqoop2\n在架构上：sqoop2引入了sqoop server，对connector实现了集中的管理\n访问方式：REST API、 JAVA API、 WEB UI以及CLI控制台方式进行访问")]),s._v(" "),e("p",[s._v("CLI方式访问，会通过交互过程界面，输入的密码信息丌被看到，同时Sqoop2引入基亍角色的安全机制，Sqoop2比Sqoop多了一个Server端。")])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("sqoop1与sqoop2优缺点比较")])]),s._v(" "),e("ul",[e("li",[e("p",[s._v("sqoop1优点架构部署简单\nsqoop1的缺点命令行方式容易出错，格式紧耦合，无法支持所有数据类型，安全机制不够完善，例如密码暴漏，安装需要root权限，connector必须符合JDBC模型")])]),s._v(" "),e("li",[e("p",[s._v("sqoop2的优点多种交互方式，命令行，web UI，rest API，conncetor集中化管理，所有的链接安装在sqoop server上，完善权限管理机制，connector规范化，仅仅负责数据的读写。")])]),s._v(" "),e("li",[e("p",[s._v("sqoop2的缺点，架构稍复杂，配置部署更繁琐。")])])])])]),s._v(" "),e("h2",{attrs:{id:"_3-工作机制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-工作机制"}},[s._v("#")]),s._v(" 3. 工作机制")]),s._v(" "),e("p",[s._v("将导入或导出命令翻译成mapreduce程序来实现")]),s._v(" "),e("p",[s._v("在翻译出的mapreduce中主要是对inputformat和outputformat进行定制")]),s._v(" "),e("h2",{attrs:{id:"_4-sqoop-实战及原理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-sqoop-实战及原理"}},[s._v("#")]),s._v(" 4. Sqoop 实战及原理")]),s._v(" "),e("h3",{attrs:{id:"_4-1-sqoop安装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-sqoop安装"}},[s._v("#")]),s._v(" 4.1 "),e("strong",[s._v("sqoop")]),s._v("安装")]),s._v(" "),e("p",[s._v("安装sqoop的前提是已经具备java和hadoop的环境")]),s._v(" "),e("p",[s._v("具体安装不是和安装方式可以自行选择，我们这里采用CDH安装。")]),s._v(" "),e("p",[e("img",{attrs:{src:a(474),alt:""}})]),s._v(" "),e("p",[s._v("验证启动")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@thtf-02 java"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# sqoop version")]),s._v("\nWarning: /opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/bin/"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("/lib/sqoop/"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("/accumulo does not exist"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v(" Accumulo imports will fail.\nPlease "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$ACCUMULO_HOME")]),s._v(" to the root of your Accumulo installation.\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v("/03/29 "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(":17:46 INFO sqoop.Sqoop: Running Sqoop version: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.4")]),s._v(".6-cdh5.16.1\nSqoop "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.4")]),s._v(".6-cdh5.16.1\n"),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("git")]),s._v(" commit "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("id")]),s._v(" \nCompiled by jenkins on Wed Nov "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("21")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("21")]),s._v(":32:45 PST "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("2018")]),s._v("\n")])])]),e("h2",{attrs:{id:"_5-sqoop-的数据导入"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-sqoop-的数据导入"}},[s._v("#")]),s._v(" 5.  Sqoop 的数据导入")]),s._v(" "),e("p",[s._v("“导入工具”导入单个表从RDBMS到HDFS。表中的每一行被视为HDFS的记录。所有记录都存储为文本文件的文本数据（或者Avro、sequence文件等二进制数据）")]),s._v(" "),e("h3",{attrs:{id:"_5-1-列举出所有的数据库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-列举出所有的数据库"}},[s._v("#")]),s._v(" 5.1 列举出所有的数据库")]),s._v(" "),e("p",[s._v("命令行查看帮助")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop list‐databases ‐‐help ")]),s._v("\n")])])]),e("p",[s._v("列出指定主机所有的数据库")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop list‐databases ‐‐connect jdbc:mysql://192.168.1.7:3306/ ‐‐ username root ‐‐password 123456")]),s._v("\n")])])]),e("h3",{attrs:{id:"_5-2-查看某一个数据库下面的所有数据表"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-查看某一个数据库下面的所有数据表"}},[s._v("#")]),s._v(" 5.2 查看某一个数据库下面的所有数据表")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop list‐tables ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456")]),s._v("\n")])])]),e("p",[s._v("如果出现连接拒绝，则在目标的mysql的数据库中执行以下命令:")]),s._v(" "),e("p",[s._v("开启windows的远程连接权限")]),s._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[s._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("GRANT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALL")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIVILEGES")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ON")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TO")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'root'")]),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("@'%'")]),s._v(" IDENTIFIED "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'yourpassword'")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WITH")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("GRANT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("OPTION")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \nmysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" FLUSH "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIVILEGES")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),e("h3",{attrs:{id:"_5-3-导入数据库表数据到-hdfs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-导入数据库表数据到-hdfs"}},[s._v("#")]),s._v(" 5.3 导入数据库表数据到 HDFS")]),s._v(" "),e("p",[s._v("下面的命令用于从MySQL数据库服务器中的emp表导入HDFS")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐username root ‐‐ password 123456 ‐‐table emp ‐‐m 1")]),s._v("\n")])])]),e("blockquote",[e("p",[s._v("注：--m :  指定maptask个数")])]),s._v(" "),e("h3",{attrs:{id:"_5-4-导入到-hdfs-指定目录"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-导入到-hdfs-指定目录"}},[s._v("#")]),s._v(" 5.4 导入到 HDFS 指定目录")]),s._v(" "),e("p",[s._v("在导入表数据到HDFS使用Sqoop导入工具，我们可以指定目标目录。")]),s._v(" "),e("p",[s._v("使用参数 --target-dir来指定导出目的地，")]),s._v(" "),e("p",[s._v("使用参数—delete-target-dir来判断导出目录是否存在，如果存在就删掉")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐delete‐target‐dir ‐‐table emp ‐‐target‐dir /sqoop/emp ‐‐m 1")]),s._v("\n")])])]),e("p",[s._v("默认，它会用逗号（，）分隔emp_add表的数据和字段。")]),s._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("1201,gopal,manager,50000,TP \n1202,manisha,Proof reader,50000,TP \n1203,khalil,php dev,30000,AC \n1204,prasanth,php dev,30000,AC \n1205,kranthi,admin,20000,TP\n")])])]),e("h3",{attrs:{id:"_5-5-导入到-hdfs-指定目录并指定字段之间的分隔符"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-5-导入到-hdfs-指定目录并指定字段之间的分隔符"}},[s._v("#")]),s._v(" 5.5 导入到 HDFS 指定目录并指定字段之间的分隔符")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐delete‐target‐dir ‐‐table emp ‐‐target‐dir /sqoop/emp2 ‐‐m 1 ‐‐fields‐terminated‐by '\\t'")]),s._v("\n")])])]),e("h3",{attrs:{id:"_5-6-导入关系表到-hive"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-6-导入关系表到-hive"}},[s._v("#")]),s._v(" 5.6 导入关系表到 HIVE")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("第一步：拷贝"),e("strong",[s._v("jar")]),s._v("包（如果是使用CDH安装则不需要此步骤）")]),s._v(" "),e("p",[s._v("将我们mysql表当中的数据直接导入到hive表中的话，我们需要将hive的一个叫做hive-exec-3.1.1.jar 的jar包拷贝到sqoop的lib目录下")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#cp /export/servers/apache‐hive‐3.1.1‐bin/lib/hive‐exec‐3.1.1.jar /export/servers/sqoop‐1.4.7.bin__hadoop‐2.6.0/lib")]),s._v("\n")])])])]),s._v(" "),e("li",[e("p",[s._v("第二步：准备"),e("strong",[s._v("hive")]),s._v("数据库与表")]),s._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[s._v("hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("database")]),s._v(" sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" external "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("name string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("deg string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("salary "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("dept string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("row")]),s._v(" format delimited "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("fields")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("terminated")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\001'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])])]),s._v(" "),e("li",[e("p",[s._v("第三步：开始导入")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐table emp ‐‐fields‐terminated‐by '\\001' ‐ ‐hive‐import ‐‐hive‐table sqooptohive.emp_hive ‐‐hive‐overwrite ‐‐delete‐ target‐dir ‐‐m 1")]),s._v("\n")])])])]),s._v(" "),e("li",[e("p",[s._v("第四步："),e("strong",[s._v("hive")]),s._v("表数据查看")]),s._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[s._v("hive"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nOK\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1201")]),s._v("    gopal   manager "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("000")]),s._v("  tp\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1202")]),s._v("    manisha Proof reader    "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("000")]),s._v("  tp\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1203")]),s._v("    khalil  java dev        "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("000")]),s._v("  tp\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1204")]),s._v("    prasanth        java dev        "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("000")]),s._v("  tp\n"),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1205")]),s._v("    kranthi java dev        "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("000")]),s._v("  tp\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Time")]),s._v(" taken: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.711")]),s._v(" seconds"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Fetched: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("row")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])])])]),s._v(" "),e("h3",{attrs:{id:"_5-7-导入关系表到-hive-并自动创建-hive-表"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-7-导入关系表到-hive-并自动创建-hive-表"}},[s._v("#")]),s._v(" 5.7 导入关系表到 Hive 并自动创建 Hive 表")]),s._v(" "),e("p",[s._v("我们也可以通过命令来将我们的mysql的表直接导入到hive表当中去")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐table emp_conn ‐‐hive‐import ‐m 1 ‐‐hive‐database sqooptohive")]),s._v("\n")])])]),e("p",[s._v("通过这个命令，我们可以直接将我们mysql表当中的数据以及表结构一起倒入到hive当中去")]),s._v(" "),e("h3",{attrs:{id:"_5-8-导入表数据子集"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-8-导入表数据子集"}},[s._v("#")]),s._v(" 5.8 导入表数据子集")]),s._v(" "),e("p",[s._v('我们可以导入表的使用Sqoop导入工具，"where"子句的一个子集。它执行在各自的数据')]),s._v(" "),e("p",[s._v("库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。")]),s._v(" "),e("p",[s._v("where子句的语法如下：")]),s._v(" "),e("p",[s._v("​\t按照条件进行查找，通过—where参数来查找表emp_add当中city字段的值为sec-bad的所有数据导入到hdfs上\t面去")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import \\ ")]),s._v("\n‐‐connect jdbc:mysql://192.168.1.7:3306/userdb "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐username root ‐‐password "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("123456")]),s._v(" ‐‐table emp_add "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐target‐dir /sqoop/emp_add ‐m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" ‐‐delete‐target‐dir "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐where "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"city = 'sec‐bad'\"")]),s._v("\n")])])]),e("h3",{attrs:{id:"_5-9-sql-语句查找导入-hdfs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-9-sql-语句查找导入-hdfs"}},[s._v("#")]),s._v(" 5.9 SQL 语句查找导入 HDFS")]),s._v(" "),e("p",[s._v("我们还可以通过 –query参数来指定我们的sql语句，通过sql语句来过滤我们的数据进行导入")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import \\ ")]),s._v("\n‐‐connect jdbc:mysql://192.168.1.7:3306/userdb "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n‐‐username root ‐‐password "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("123456")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐delete‐target‐dir ‐m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐query "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'select email from emp_conn where 1=1 and "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$CONDITIONS")]),s._v("'")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐target‐dir /sqoop/emp_conn\n")])])]),e("h3",{attrs:{id:"_5-10-增量导入"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-10-增量导入"}},[s._v("#")]),s._v(" 5.10 增量导入")]),s._v(" "),e("p",[s._v("在实际工作当中，数据的导入，很多时候都是只需要导入增量数据即可，并不需要将表中的数据全部导入到hive或者hdfs当中去，肯定会出现重复的数据的状况，所以我们一般都是选用一些字段进行增量的导入，为了支持增量的导入，sqoop也给我们考虑到了这种情况并且支持增量的导入数据")]),s._v(" "),e("p",[s._v("增量导入是仅导入新添加的表中的行的技术。")]),s._v(" "),e("p",[s._v("它需要添加‘incremental’, ‘check-column’, 和 ‘last-value’选项来执行增量导入。")]),s._v(" "),e("p",[s._v("下面的语法用于Sqoop导入命令增量选项。")]),s._v(" "),e("p",[s._v("**第一种增量导入使用上面的选项来实现 **")]),s._v(" "),e("p",[s._v("导入emp表当中id大于1202的所有数据")]),s._v(" "),e("blockquote",[e("p",[s._v("注意：增量导入的时候，一定不能加参数--delete-target-dir否则会报错")])]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop import \\ ")]),s._v("\n‐‐connect jdbc:mysql://192.168.1.7:3306/userdb "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐username root "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐password "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("123456")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐table emp "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐incremental append "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐check‐column "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("id")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐last‐value "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1202")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐target‐dir /sqoop/increment\n")])])]),e("p",[e("strong",[s._v("第二种增量导入通过")]),s._v("--where**条件来实现 **")]),s._v(" "),e("p",[s._v("或者我们使用--where来进行控制数据的选取会更加精准")]),s._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("#sqoop import \\ \n‐‐connect jdbc:mysql://192.168.1.7:3306/userdb \\ \n‐‐username root \\ \n‐‐password 123456 \\ \n‐‐table emp \\ \n‐‐incremental append \\ \n‐‐where \"create_time > '2018‐06‐17 00:00:00' and create_time < '2018‐06‐ 17 23:59:59'\" \\\n‐‐target‐dir /sqoop/incement2 \\ \n‐‐check‐column id \\ \n‐‐m 1\n")])])]),e("h2",{attrs:{id:"_6-sqoop-的数据导出"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6-sqoop-的数据导出"}},[s._v("#")]),s._v(" 6. Sqoop 的数据导出")]),s._v(" "),e("ol",[e("li",[e("p",[s._v("将数据从HDFS把文件导出到RDBMS数据库")]),s._v(" "),e("p",[s._v("导出前，目标表必须存在于目标数据库中。")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("默认操作是从将文件中的数据使用INSERT语句插入到表中")])]),s._v(" "),e("li",[e("p",[s._v("更新模式下，是生成UPDATE语句更新表数据")])])])])]),s._v(" "),e("h3",{attrs:{id:"_6-1-hdfs-导出到-mysql"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-hdfs-导出到-mysql"}},[s._v("#")]),s._v(" 6.1 HDFS 导出到 MySQL")]),s._v(" "),e("p",[s._v("数据是在HDFS当中的如下目录/sqoop/emp，数据内容如下")]),s._v(" "),e("div",{staticClass:"language-xml extra-class"},[e("pre",{pre:!0,attrs:{class:"language-xml"}},[e("code",[s._v("1201,gopal,manager,50000,TP,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1\n1202,manisha,Proof reader,50000,TP,2018-06-15 18:54:32.0,2018-06-17 20:26:08.0,1 \n1203,khalil,php dev,30000,AC,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1 \n1204,prasanth,php dev,30000,AC,2018-06-17 18:54:32.0,2018-06-17 21:05:52.0,0 \n1205,kranthi,admin,20000,TP,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1\n")])])]),e("p",[s._v("第一步：创建"),e("strong",[s._v("mysql")]),s._v("表")]),s._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" emp_out "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v(" \n    id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    name "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    deg "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    salary "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    dept "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    create_time "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TIMESTAMP")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    update_time "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TIMESTAMP")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ON")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UPDATE")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    is_delete "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'1'")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INNODB")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),e("p",[s._v("第二步：执行导出命令")]),s._v(" "),e("p",[s._v("通过export来实现数据的导出，将hdfs的数据导出到mysql当中去")]),s._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sqoop export \\ ")]),s._v("\n‐‐connect jdbc:mysql://192.168.1.7:3306/userdb "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐username root ‐‐password "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("123456")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐table emp_out "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐export‐dir /sqoop/emp "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v(" \n‐‐input‐fields‐terminated‐by "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('","')]),s._v("\n")])])])])}),[],!1,null,null,null);t.default=r.exports}}]);