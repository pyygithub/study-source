(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{427:function(t,s,a){t.exports=a.p+"assets/img/hbase.93edf177.png"},428:function(t,s,a){t.exports=a.p+"assets/img/hbase_sql.959a0d0b.png"},429:function(t,s,a){t.exports=a.p+"assets/img/hbase_table.1b989bf7.png"},430:function(t,s,a){t.exports=a.p+"assets/img/hbase_jz.3ac5b219.png"},431:function(t,s,a){t.exports=a.p+"assets/img/hbase_regin.3283b72d.png"},432:function(t,s,a){t.exports=a.p+"assets/img/hbase_zk.1a45a579.png"},433:function(t,s,a){t.exports=a.p+"assets/img/hbase_scan.d6d8c032.png"},434:function(t,s,a){t.exports=a.p+"assets/img/hbase_memory.70808c99.png"},435:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs_log1.44b22be9.png"},436:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs_log2.306c9b8c.png"},437:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs_log3.0acba47d.png"},438:function(t,s,a){t.exports=a.p+"assets/img/cdh_hbase.fa0f938d.png"},439:function(t,s,a){t.exports=a.p+"assets/img/hbase_table1.21e70f48.png"},440:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs.a9abf4d8.png"},441:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs1.3c560501.png"},442:function(t,s,a){t.exports=a.p+"assets/img/hbase_hdfs2.99b2c73a.png"},443:function(t,s,a){t.exports=a.p+"assets/img/hbase_byte.ff2c0d41.png"},510:function(t,s,a){"use strict";a.r(s);var n=a(19),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"hbase"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#hbase"}},[t._v("#")]),t._v(" HBase")]),t._v(" "),n("p",[n("img",{attrs:{src:a(427),alt:""}})]),t._v(" "),n("p",[t._v("HDFS：Hadoop分布式文件系统，适合非结构化数据的存储以及读取。")]),t._v(" "),n("p",[t._v("Apache HBase建立在HDFS之上的分布式、基于列存储的非关系型数据库；具有可靠、稳定、自动容错、多版本特性。")]),t._v(" "),n("p",[t._v("HBase实际上是Google BigTable项目的开源实现，它适合于海量的大规模（数十亿行、数百万列）的结构化数据存储。")]),t._v(" "),n("p",[t._v("当需要随机、实时读写访问大数据时,使用HBase。")]),t._v(" "),n("h2",{attrs:{id:"_1-概念特性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-概念特性"}},[t._v("#")]),t._v(" 1. 概念特性")]),t._v(" "),n("p",[t._v("HBASE是一个"),n("strong",[t._v("数据库")]),t._v("----可以提供数据的实时"),n("strong",[t._v("随机读写")])]),t._v(" "),n("p",[t._v("HBASE与mysql、oralce、db2、sqlserver等关系型数据库不同，它是一个NoSQL数据库（非关系型数据库）")]),t._v(" "),n("p",[t._v("Hbase的表模型与关系型数据库的表模型不同：")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("Hbase的表没有固定的字段定义")])]),t._v(" "),n("li",[n("p",[t._v("Hbase的表中每行存储的都是一些key-value对")])]),t._v(" "),n("li",[n("p",[t._v("Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族")])]),t._v(" "),n("li",[n("p",[t._v("Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中")])]),t._v(" "),n("li",[n("p",[t._v("Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复")])]),t._v(" "),n("li",[n("p",[t._v("Hbase中的数据，包含行键，包含key，包含value，HBase中的数据都是字符串（底层存储采用的是byte[]），没有类型，hbase不负责为用户维护数据类型")])]),t._v(" "),n("li",[n("p",[t._v("HBASE对事务的支持很差")])])]),t._v(" "),n("p",[t._v("HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：")]),t._v(" "),n("p",[n("strong",[t._v("Hbase的表数据存储在HDFS文件系统中")])]),t._v(" "),n("p",[t._v("从而，hbase具备如下特性：存储容量可以线性扩展； 数据存储的安全性可靠性极高！")]),t._v(" "),n("h2",{attrs:{id:"_2-各种数据库之间的差别比较"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-各种数据库之间的差别比较"}},[t._v("#")]),t._v(" 2. 各种数据库之间的差别比较")]),t._v(" "),n("p",[n("img",{attrs:{src:a(428),alt:""}})]),t._v(" "),n("h3",{attrs:{id:"_2-1-hbase和hive区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-hbase和hive区别"}},[t._v("#")]),t._v(" 2.1 HBase和Hive区别")]),t._v(" "),n("h4",{attrs:{id:"_2-1-1-hive-数据仓库的理解"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-1-hive-数据仓库的理解"}},[t._v("#")]),t._v(" 2.1.1 Hive 数据仓库的理解")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("仓库就是存放历史数据存的地方，反复对历史数据进行读操作，统计分析操作，历史数据不需要修改。")])]),t._v(" "),n("li",[n("p",[t._v("Hive严格意义上来讲不能算是数据库。")]),t._v(" "),n("p",[t._v("Hive与Hbase巨大的区别在于，Hive底层依赖的文件系统HDFS中的数据是用户提交的，没有固定的格式，可以理解成按照分隔符分割的简单文本，而不是精心设计的文件（如Mysql那样精心设计的文件加上mysql中共的软件系统，可以对数据进行随机的访问和修改操作），Hive只能对这些数据进行读取，分析，不能对修改和跟新数据。")])]),t._v(" "),n("li",[n("p",[t._v("mysql也当然具备做为数据仓库的功能和能力，但是数据量太大是，mysql不适合，mysql适于联机事务处理（在线实时交互）。")])])]),t._v(" "),n("h4",{attrs:{id:"_2-1-2-hbase"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-2-hbase"}},[t._v("#")]),t._v(" 2.1.2 HBase")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("同msyql一样，底层的文件系统的精心设计的，Hbase的底层文件系统也是HDFS。")])]),t._v(" "),n("li",[n("p",[t._v("具有联机事务处理数据库的特性（"),n("strong",[t._v("快速")]),t._v(" "),n("strong",[t._v("实时")]),t._v("操作数据库，增删改查）。")])]),t._v(" "),n("li",[n("p",[t._v("Hbase本身的特性：")]),t._v(" "),n("ul",[n("li",[t._v("文件系统：HDFS（表可以很大很大）")]),t._v(" "),n("li",[t._v("分布式系统")]),t._v(" "),n("li",[t._v("nosql表结构")])])])]),t._v(" "),n("h2",{attrs:{id:"_3-hbase-特性与表结构"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-hbase-特性与表结构"}},[t._v("#")]),t._v(" 3. HBase 特性与表结构")]),t._v(" "),n("p",[n("img",{attrs:{src:a(429),alt:"Hbase的逻辑结构"}})]),t._v(" "),n("p",[n("strong",[t._v("列族")]),t._v("：KV分为若干的大类：，如上表所示。")]),t._v(" "),n("ol",[n("li",[t._v("每个列族中的kv数据可以随意存放，key可以不同，没有严格要求，完全有用户决定，当然一般使用情况下，数据是规整的；")])]),t._v(" "),n("p",[t._v("如：下表是可以的，但是为了数据的规整，一般不建议随意为key起名字，最好保持一致。")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("rowkey")]),t._v(" "),n("th",[t._v("base_info")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("001")]),t._v(" "),n("td",[t._v("name:jj, age:12, sex:mal")])]),t._v(" "),n("tr",[n("td",[t._v("002")]),t._v(" "),n("td",[t._v("nick:ls, age:15, xb:male")])])])]),t._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[n("p",[t._v("同一个列祖中的kv的个数也是灵活的，可以省略某些kv")]),t._v(" "),n("p",[t._v("**cell：**同一个数据可以保存多个值")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("一个kv就是一个cell")])]),t._v(" "),n("li",[n("p",[t._v("一个key可有有多个版本的值")])]),t._v(" "),n("li",[n("p",[t._v("时间戳作为版本")])])])])]),t._v(" "),n("h2",{attrs:{id:"_4-hbase-整体工作机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-hbase-整体工作机制"}},[t._v("#")]),t._v(" 4. HBase 整体工作机制")]),t._v(" "),n("h3",{attrs:{id:"_4-1-工作机制示意图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-工作机制示意图"}},[t._v("#")]),t._v(" 4.1 工作机制示意图")]),t._v(" "),n("p",[n("img",{attrs:{src:a(430),alt:""}})]),t._v(" "),n("p",[t._v("Hbase集群中有两个角色")]),t._v(" "),n("p",[n("strong",[t._v("region server")])]),t._v(" "),n("p",[n("strong",[t._v("master")])]),t._v(" "),n("p",[t._v("region server负责数据的逻辑处理（增删改查），"),n("strong",[t._v("region server对数据的操作是不经过master")]),t._v("。某一个瞬间master挂了，regionserver还是可以正常服务的，但是一定时间之后，万一某一个regionserver挂了，该regionserver负责的任务得不到重新分配，就会出问题。")]),t._v(" "),n("h3",{attrs:{id:"_4-2-存储问题-分散存储"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-存储问题-分散存储"}},[t._v("#")]),t._v(" 4.2 存储问题（分散存储）")]),t._v(" "),n("p",[t._v("按照region划分范围存储（region目录还细分为列族目录，列族目录下才存放具体的文件）")]),t._v(" "),n("h3",{attrs:{id:"_4-3-查询问题-分布式-分任务查询"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-查询问题-分布式-分任务查询"}},[t._v("#")]),t._v(" 4.3 查询问题（分布式：分任务查询）")]),t._v(" "),n("p",[t._v("HBase底层文件系统是HDFS，HBase中的表最终也会落地HDFS，那么Hbase的一张表可以很大很大，表中的数据不断的增加增加存储也是可以的，但是怎么查询呢？")]),t._v(" "),n("p",[t._v("当请求特别多的时候，一台HBase服务器（region server）是不行的，HBase是一个分布式的系统，当有多个Hbase提供服务的时候，某一次客户端的请求具体由那个服务器来处理呢？")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("当某一台服务器挂了，谁来接替它的工作，如何接替？")]),t._v(" "),n("p",[t._v("​\t**解决：**服务器需要分任务（分布式系统里肯定是要分任务的）")]),t._v(" "),n("p",[t._v("​\t一台服务器，负责Hbase中某个表的某一个部分。")])]),t._v(" "),n("li",[n("p",[t._v("如何界定部分？")]),t._v(" "),n("p",[t._v("​\t需要"),n("strong",[t._v("划分范围："),n("strong",[t._v("按照")]),t._v("行健范围")])])])]),t._v(" "),n("p",[t._v("这样通过分任务之后就是一个"),n("strong",[t._v("分布式系统。"),n("strong",[t._v("不同的regionServer可以")]),t._v("并行")]),t._v("的去访问hdfs中的数据（表数据）"),n("strong",[t._v("，"),n("strong",[t._v("这样还有一个问题，若某一张表中的所有数据都存在同一个HDFS中的文件中，即使是负责同一张表的不同范围regionserver，大量的并行请求也会同时访问同一个hdfs文件，这会造成性能上的瓶颈，所以表中的数据在HDFS中是按照")]),t._v("region划分范围存储（region目录还细分为列族目录，列族目录下才存放具体的文件）")]),t._v(", 这样"),n("strong",[t._v("同一个表的不同region范围的数据落地HDFS中不同的文件中")]),t._v("。否则会造成即是分了任务一个dataNode被频繁的访问。")]),t._v(" "),n("h4",{attrs:{id:"_4-3-1-客户端读写数据时的路由流程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-1-客户端读写数据时的路由流程"}},[t._v("#")]),t._v(" 4.3.1 客户端读写数据时的路由流程")]),t._v(" "),n("p",[n("strong",[t._v("问题描述")]),t._v("：客户端怎么知道他要访问的某个region在那一台regionserver上呢？")]),t._v(" "),n("p",[t._v("master是不会保存哪些region在哪些regionserver上的，否则就是有状态的节点了，一旦master挂了，regionserver立刻无法提供服务，而事实不是这样。")]),t._v(" "),n("p",[t._v("上述信息就是所谓的索引信息，master是不会保存索引信息的，索引信息是保存在系统索引表中的。")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("索引表当然也存在于hdfs中，且只有一个region；")])]),t._v(" "),n("li",[n("p",[t._v("谁来负责查询索引表")])])]),t._v(" "),n("p",[t._v("下图所示，索引表数据的查询由hdp-02机器上的regionserver负责，那么客户端怎样知道meta数据由hdp-02负责")]),t._v(" "),n("p",[n("img",{attrs:{src:a(431),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("zookeeper上会记录元数据索引表，有哪一台regionserver负责管理。")]),t._v("　客户单端，每次访问数据之前，先查询zookeeper。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(432),alt:""}})]),t._v(" "),n("p",[t._v("下图为Zookeeper节点"),n("strong",[t._v("meta-region-server的信息")])]),t._v(" "),n("p",[n("strong",[t._v("访问流程：")])]),t._v(" "),n("ol",[n("li",[n("p",[t._v("客户端去Zookeeper上查询，负责索引表数据的regionserver；")])]),t._v(" "),n("li",[n("p",[t._v("找该台regionserver服务器，查询出客户端要访问的region数据由哪一台regionserver负责；")])]),t._v(" "),n("li",[n("p",[t._v("客户端找具体的regionserver要数据.")])])]),t._v(" "),n("p",[n("strong",[t._v("总结：")])]),t._v(" "),n("ol",[n("li",[n("p",[t._v("Hbase表中的数据是存放在hdfs中的。")])]),t._v(" "),n("li",[n("p",[t._v("regionserver只负责逻辑功能，对数据进行增删改查，不存储它负责的region的数据。")])]),t._v(" "),n("li",[n("p",[t._v("一个regionserver可以负责多个表的多个region。")])]),t._v(" "),n("li",[n("p",[t._v("region是regionServer管理数据的基本单元。")])]),t._v(" "),n("li",[n("p",[t._v("客户端查找数据不经过master。")])]),t._v(" "),n("li",[n("p",[t._v("客观端查找数据一定经过Zookeeper。")])])]),t._v(" "),n("h3",{attrs:{id:"_4-4-服务器宕机问题-借助zookeeper实现ha"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-服务器宕机问题-借助zookeeper实现ha"}},[t._v("#")]),t._v(" 4.4 服务器宕机问题（借助Zookeeper实现HA）")]),t._v(" "),n("p",[n("strong",[t._v("master对regionserver的监管，状态协调")])]),t._v(" "),n("ol",[n("li",[n("p",[t._v("所有的状态信息记录在Zookeeper里。")])]),t._v(" "),n("li",[n("p",[t._v("master"),n("strong",[t._v("负责监管")]),t._v("region server的状态，知道每一个regionserver负责哪些表的哪些region，不负责帮用户查数据，一旦发现某个region server发生故障，会找另外的一台机器来接替该region server负责的region区域。")])]),t._v(" "),n("li",[n("p",[t._v("master通过Zookeeper来获取regionserver的状态。")])]),t._v(" "),n("li",[n("p",[t._v("master通过Zookeeper监听region server，maste是没有状态的节点，master存在单点故障的风险；通过主备容灾实现HA机制。")])])]),t._v(" "),n("p",[n("strong",[t._v("master HA")])]),t._v(" "),n("p",[n("strong",[t._v("状态信息记录在Zookeeper里。")])]),t._v(" "),n("p",[t._v("可以在集群中找任意一台机器启动一个备用的master，新启的这个master会处于backup状态")]),t._v(" "),n("h3",{attrs:{id:"_4-5-hbase工作机制补充-regionserver数据管理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-hbase工作机制补充-regionserver数据管理"}},[t._v("#")]),t._v(" 4.5 Hbase工作机制补充—regionserver数据管理")]),t._v(" "),n("p",[t._v("首先在hbase的表中插入一些数据，然后来观察一下hdfs中存的数据，发现hdfs下并没有数据，但是scan明明可以查到数据的，这是怎么回事呢？")]),t._v(" "),n("p",[n("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1020536/201810/1020536-20181016094210414-521552116.png",alt:"img"}})]),t._v(" "),n("p",[t._v("scan可以查到数据。而上图hdfs中却没有数据文件。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(433),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("其实：此时此刻的数据位于内存中。")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(434),alt:""}})]),t._v(" "),n("h4",{attrs:{id:"_4-5-1-内存缓存热数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-1-内存缓存热数据"}},[t._v("#")]),t._v(" 4.5.1 内存缓存热数据")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("每个region在内存中都对应分配一块缓存空间，memstore，但是memstore毕竟有限，不会将全部的数据都存入到内存中，还是有很大的数据是存在hdfs中的。当数据量很小的时候没有必要写入到hdfs文件中，这就解释了为什么上述hdfs中没有文件数据。")]),t._v(" "),n("p",[t._v("上述用户插入的数据都保存在了内存中，这样速度会比存入hdfs中快很多，但是又不能吧全部数据都存入到内存中，内存中只会保存一些"),n("strong",[t._v("热数据【刚刚被访问过的，刚刚被插入的数据】")]),t._v("。")]),t._v(" "),n("p",[t._v("如果有人找regionserver查数据是，regionserver内存中没有该数据，就会去hdfs中查找，找到之后作为热数据，然后缓存在内存中，超过一段时间没有人访问就不是热数据了，就不会继续保存在内存中。")])]),t._v(" "),n("li",[n("p",[t._v("数据保存在内存中就有风险，万一没有来的落地hdfs，"),n("strong",[t._v("宕机")]),t._v("了，内存中的数据会丢失，怎么办？")]),t._v(" "),n("p",[t._v("解决方案：regionserver一方面在自己内存中写数据，一方面在hdfs中写日志，一旦宕机后，master找来替换机器后，该机器会读取日志信息，还原内存中的数据。")])])]),t._v(" "),n("p",[n("img",{attrs:{src:a(435),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(436),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(437),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("总结：")])]),t._v(" "),n("p",[n("strong",[t._v("1、热数据存储")])]),t._v(" "),n("p",[n("strong",[t._v("2、日志记录")])]),t._v(" "),n("h4",{attrs:{id:"_4-5-2-持久化到hdfs"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-2-持久化到hdfs"}},[t._v("#")]),t._v(" 4.5.2 持久化到hdfs")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("当内存中的数据插满时候，数据会持久化到hdfs中")])]),t._v(" "),n("li",[n("p",[t._v("当hbase退出时候，数据也会持久化到hdfs中")])])]),t._v(" "),n("h2",{attrs:{id:"_5-安装-hbase"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5-安装-hbase"}},[t._v("#")]),t._v(" 5. 安装 HBase")]),t._v(" "),n("h3",{attrs:{id:"安装hbase"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#安装hbase"}},[t._v("#")]),t._v(" 安装HBase")]),t._v(" "),n("p",[t._v("HBase是Google Bigtable的开源实现，它利用Hadoop HDFS作为其文件存储系统，利用Hadoop MapReduce来处理HBase中的海量数据，利用Zookeeper作为协同服务。所以安装HBase之前还需要安装zookeeper和hdfs。")]),t._v(" "),n("p",[t._v("如果是Apache hadoop就下载相应文件并修改配置文件安装。我用的是cloudera hadoop就直接在集群管理界面添加服务。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(438),alt:""}})]),t._v(" "),n("h2",{attrs:{id:"_6-hbase-客户端"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-hbase-客户端"}},[t._v("#")]),t._v(" 6. HBase 客户端")]),t._v(" "),n("h3",{attrs:{id:"_6-1-命令行客户端"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-命令行客户端"}},[t._v("#")]),t._v(" 6.1 命令行客户端")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#bin/hbase shell")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#hbase(main):001:0> list     // 查看表")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#hbase(main):002:0> status   // 查看集群状态")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#hbase(main):003:0> version  // 查看集群版本")]),t._v("\n")])])]),n("p",[t._v("进入命令行客户端，help查看都有哪些命令【命令分为不同的组别 ddl dml tools replication...】。")]),t._v(" "),n("h4",{attrs:{id:"_6-1-1-建表"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-1-建表"}},[t._v("#")]),t._v(" 6.1.1 建表")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("create "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra_info'")]),t._v("\n\t\t表名      \t列族名   \t\t列族名\n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":004:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" create "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra_info'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.4210")]),t._v(" seconds\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Hbase::Table - t_user_info\n")])])]),n("p",[n("strong",[t._v("查看HBase建表后的状态")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(439),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("HDFS中的数据")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(440),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(441),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(442),alt:""}})]),t._v(" "),n("h4",{attrs:{id:"_6-1-2-插入数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-2-插入数据"}},[t._v("#")]),t._v(" 6.1.2 插入数据")]),t._v(" "),n("p",[n("strong",[t._v("put命令")])]),t._v(" "),n("p",[n("strong",[t._v("语法：")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'表名'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'行健'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'列族:key'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'value'")]),t._v("\n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":004:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:username'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'zhangsan'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2250")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":005:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:age'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'18'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0180")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":006:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:sex'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'female'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0250")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":007:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra_info:career'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'it_java'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0150")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":008:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'002'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:username'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lisi'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0130")]),t._v(" seconds\n")])])]),n("h4",{attrs:{id:"_6-1-3-查询数据方式一-get-单行查询"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-3-查询数据方式一-get-单行查询"}},[t._v("#")]),t._v(" 6.1.3 查询数据方式一：get 单行查询")]),t._v(" "),n("p",[t._v("语法：")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("-- 返回该行全部数据\nget "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'表名'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'行健'")]),t._v("\n\n-- 返回该行指定列族：key的值\nget "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'表名'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'行健'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'列族:key'")]),t._v("\n")])])]),n("p",[t._v("特性："),n("strong",[t._v("HBase会对 ' 列族：key ' 进行字典序排序")])]),t._v(" "),n("p",[n("strong",[t._v("timestamp：是key的版本号")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":001:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" get "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v("\nCOLUMN                       CELL\n base_info:age               "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464683099")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v("\n base_info:sex               "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464711338")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("female\n base_info:username          "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464658247")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("zhangsan\n extra_info:career           "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464797473")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("it_java\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2740")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":002:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" get "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:username'")]),t._v("\nCOLUMN                       CELL\n base_info:username          "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464658247")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("zhangsan\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0260")]),t._v(" seconds\n\n")])])]),n("h4",{attrs:{id:"_6-1-4-查询数据方式二-scan-扫描"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-4-查询数据方式二-scan-扫描"}},[t._v("#")]),t._v(" 6.1.4 查询数据方式二：scan 扫描")]),t._v(" "),n("p",[n("strong",[t._v("scan是全表扫描")])]),t._v(" "),n("p",[t._v("特性：")]),t._v(" "),n("p",[n("strong",[t._v("1、先按照行健排序。")])]),t._v(" "),n("p",[n("strong",[t._v("2、同一行健，按照key的字典序排序。")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":012:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" scan "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v("\nROW              COLUMN+CELL\n 001             "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_info:age, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464683099")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v("\n 001             "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_info:sex, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464711338")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("female\n 001             "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_info:username, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464658247")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("zhangsan\n 001             "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_info:career, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464797473")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("it_java\n 002             "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_info:username, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1585464828257")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("lisi\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0190")]),t._v(" seconds\n")])])]),n("h4",{attrs:{id:"_6-1-5-delete-删除一个kv数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-5-delete-删除一个kv数据"}},[t._v("#")]),t._v(" 6.1.5 delete 删除一个kv数据")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":021:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" delete "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'base_info:sex'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0390")]),t._v(" seconds\n")])])]),n("h4",{attrs:{id:"_6-1-6-deleteall-删除整行数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-6-deleteall-删除整行数据"}},[t._v("#")]),t._v(" 6.1.6 deleteall 删除整行数据")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":024:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" deleteall "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0090")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":025:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" get "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v(","),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'001'")]),t._v("\nCOLUMN                            CELL                                                                                            \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0110")]),t._v(" seconds\n")])])]),n("h4",{attrs:{id:"_6-1-7-删除整个表"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-7-删除整个表"}},[t._v("#")]),t._v(" 6.1.7 删除整个表")]),t._v(" "),n("p",[t._v("语法：")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("-- 停用表\ndisable 表名\n-- 删除表\ndrop 表名\n")])])]),n("p",[t._v("删除表之前先要停用表。")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":028:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" disable "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.3640")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":029:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" drop "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t_user_info'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.2950")]),t._v(" seconds\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":030:"),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" list\nTABLE                                                                                                                             \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0130")]),t._v(" seconds\n")])])]),n("h3",{attrs:{id:"_6-2-客户端api"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-客户端api"}},[t._v("#")]),t._v(" 6.2 客户端api")]),t._v(" "),n("p",[t._v("如何描述一个表？")]),t._v(" "),n("p",[t._v("如何创建一个表？")]),t._v(" "),n("p",[t._v("删除一个表？")]),t._v(" "),n("p",[t._v("修改一个表？")]),t._v(" "),n("blockquote",[n("p",[t._v("步骤：")]),t._v(" "),n("ol",[n("li",[t._v("构建连接")]),t._v(" "),n("li",[t._v("从连接中取到一个表DDL操作工具admin")]),t._v(" "),n("li",[t._v("admin.createTable(表描述对象);")]),t._v(" "),n("li",[t._v("admin.disableTable(表名);")]),t._v(" "),n("li",[t._v("admin.deleteTable(表名);")]),t._v(" "),n("li",[t._v("admin.modifyTable(表名，表描述对象)。")])])]),t._v(" "),n("h4",{attrs:{id:"_6-2-1-创建连接对象"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-1-创建连接对象"}},[t._v("#")]),t._v(" 6.2.1 创建连接对象")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HBaseConfiguration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HColumnDescriptor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HTableDescriptor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Admin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Connection")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConnectionFactory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("regionserver"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BloomType")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Connection")]),t._v(" conn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Before")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getConn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// new Configuration() 加载的是hadoop的配置文件：core-site.xml hdfs-site.xml，不会加载hbase-site.xml")]),t._v("\n　　　　 "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 构建一个连接对象")]),t._v("\n　　　　 "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Hbase提供了HbaseConfiguraton 用来加载hbase-site.xml")]),t._v("\n　　　　 "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HBaseConfiguration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 会自动加载hbase-site.xml")]),t._v("\n　　　　 "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 客户端查询数据的路由流程可知：客户端需要先链接 Zookeeper 获取索引表")]),t._v("\n        conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("set")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase.zookeeper.quorum"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"thtf-01:2181,thtf-02:2181,thtf-03:2181"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n　　　　 "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建链接对象")]),t._v("\n        conn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConnectionFactory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("createConnection")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"_6-2-2-ddl操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-2-ddl操作"}},[t._v("#")]),t._v(" 6.2.2 DDL操作")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取一个操作指定表的table对象,进行DML操作")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t_user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("h5",{attrs:{id:"增加数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#增加数据"}},[t._v("#")]),t._v(" 增加数据")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("Table对象，进行DML操作;")])]),t._v(" "),n("li",[n("p",[t._v("数据封装对象put;")])]),t._v(" "),n("li",[n("p",[t._v("Table.put(put) | Table.put(List"),n("put",[t._v("puts);")])],1)])]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 增\n     * 改:put来覆盖\n     * @throws Exception \n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testPut")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取一个操作指定表的table对象,进行DML操作")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t_user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 构造要插入的数据为一个Put类型(一个put对象只能对应一个rowkey)的对象")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"001"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"username"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"张三"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"18"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"北京"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),t._v(" put2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"002"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"username"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"李四"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"28"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        put2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"上海"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" puts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        puts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        puts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("put2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 插进去")]),t._v("\n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("puts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("    \n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 循环插入大量数据\n     * @throws Exception \n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testManyPuts")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" puts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),t._v(" put "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"username"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"张三"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"北京"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            \n            puts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        \n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("puts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"删除数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#删除数据"}},[t._v("#")]),t._v(" 删除数据")]),t._v(" "),n("p",[t._v("对称结构，插入的时候需要Put对象")]),t._v(" "),n("p",[t._v("删除的时候，需要Delete对象")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 删\n     * @throws Exception \n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testDelete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 构造一个对象封装要删除的数据信息　　　　 ")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 全部删除")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delete")]),t._v(" delete1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"001"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 删除指定的key")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delete")]),t._v(" delete2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"002"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("　\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// qualifier为用户意义上的key，hbase中 family+qualifier 为一个key")]),t._v("\n        delete2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("addColumn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" dels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        dels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        dels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"修改数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#修改数据"}},[t._v("#")]),t._v(" 修改数据")]),t._v(" "),n("p",[t._v("使用put来覆盖")]),t._v(" "),n("h5",{attrs:{id:"查看数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#查看数据"}},[t._v("#")]),t._v(" 查看数据")]),t._v(" "),n("p",[t._v("qualifier为用户意义上的key，hbase中 family+qualifier 为一个key")]),t._v(" "),n("p",[t._v("对称结构，插入的时候需要Put对象")]),t._v(" "),n("p",[t._v("删除的时候，需要Delete对象")]),t._v(" "),n("p",[t._v("查看单个行键数据，需要Get对象")]),t._v(" "),n("ul",[n("li",[n("h5",{attrs:{id:"取出单行数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#取出单行数据"}},[t._v("#")]),t._v(" 取出单行数据")]),t._v(" "),n("p",[t._v("Table.get(Get)")]),t._v(" "),n("p",[t._v("可以取出该行特定 familyName：key 的 value")]),t._v(" "),n("p",[t._v("也可以遍历该行全部的value")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 查\n     * @throws Exception \n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testGet")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Get对象 指定行健　")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Get")]),t._v(" get "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"002"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 行健为002的全部数据")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),t._v(" result "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从结果中取用户指定的某个key的value")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"base_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-------------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历整行结果中的所有kv单元格　　　　 // 类似迭代器")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CellScanner")]),t._v(" cellScanner "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("cellScanner")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cellScanner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("advance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cell")]),t._v(" cell "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cellScanner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("current")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            \n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" rowArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//本kv所属的行键的字节数组")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" familyArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//列族名的字节数组")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" qualifierArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//列名的字节数据")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" valueArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// value的字节数组")]),t._v("\n            　　　　　　　"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Hbase不仅仅是存储用户数据，同时还会存储很多附加的信息，以上get方法直接将用户数据和附加数据一起返回，若想获取用户信息，需要指定其实偏移量和数据长度　")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"行键: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rowArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"列族名: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("familyArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"列名: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("qualifierArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("valueArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            \n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        \n        table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),n("li",[n("h5",{attrs:{id:"批量取出数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#批量取出数据"}},[t._v("#")]),t._v(" 批量取出数据")]),t._v(" "),n("p",[t._v("取出多个行健范围的数据，需要Scan对象")]),t._v(" "),n("p",[t._v("Table.get(Get)只能取出一个行健范围的数据；")]),t._v(" "),n("p",[t._v("如何按照行健范围取出数据？")]),t._v(" "),n("p",[t._v("table.getScanner(scan)")]),t._v(" "),n("p",[t._v("拿到一个扫描器")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 按行键范围查询数据\n     * @throws Exception \n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testScan")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Table")]),t._v(" table "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTable")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("valueOf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_info"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// Scan scan = new Scan("10".getBytes(), "10000".getBytes());')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 包含起始行键，不包含结束行键,但是如果真的想查询出末尾的那个行键，")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 那么，可以在末尾行键上拼接一个不可见的字节（\\000）　　　　 ")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Scan")]),t._v(" scan "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Scan")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10000\\000"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ResultScanner")]),t._v(" scanner "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" table"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getScanner")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scan"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Iterator")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" iterator "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scanner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("iterator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iterator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasNext")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 拿到一行数据")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),t._v(" result "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" iterator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("next")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历整行结果中的所有kv单元格")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CellScanner")]),t._v(" cellScanner "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("cellScanner")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cellScanner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("advance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cell")]),t._v(" cell "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cellScanner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("current")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                \n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" rowArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//本kv所属的行键的字节数组")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" familyArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//列族名的字节数组")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" qualifierArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//列名的字节数据")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" valueArray "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// value的字节数组")]),t._v("\n                \n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"行键: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rowArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRowLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"列族名: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("familyArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFamilyLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"列名: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("qualifierArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getQualifierLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("valueArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueOffset")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cell"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValueLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n")])])])])]),t._v(" "),n("p",[n("strong",[t._v("范围查询的细节")])]),t._v(" "),n("p",[t._v("道理：在真正的结尾行健后面，拼接一个数字0的字节")]),t._v(" "),n("p",[n("strong",[t._v("\\000是一个字节，全是0")])]),t._v(" "),n("p",[n("strong",[t._v("\\表示转义，此时后面的0不是数字0，不是字符0")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(443),alt:""}})]),t._v(" "),n("h2",{attrs:{id:"_7-hbase重要特性-排序特性-行键"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_7-hbase重要特性-排序特性-行键"}},[t._v("#")]),t._v(" 7. Hbase重要特性--排序特性（行键）")]),t._v(" "),n("p",[t._v("插入到hbase中去的数据，hbase会自动排序存储：")]),t._v(" "),n("p",[n("strong",[t._v("排序规则： 首先看行键，然后看列族名，然后看列（key）名； 按字典顺序")])]),t._v(" "),n("p",[t._v("Hbase的这个特性跟查询效率有极大的关系")]),t._v(" "),n("p",[t._v("比如：一张用来存储用户信息的表，有名字，户籍，年龄，职业....等信息")]),t._v(" "),n("p",[t._v("然后，在业务系统中经常需要：")]),t._v(" "),n("p",[t._v("查询某个省的所有用户")]),t._v(" "),n("p",[t._v("经常需要查询某个省的指定姓的所有用户")]),t._v(" "),n("p",[n("strong",[t._v("思路")]),t._v("：如果能将相同省的用户在hbase的存储文件中连续存储，并且能将相同省中相同姓的用户连续存储，那么，上述两个查询需求的效率就会提高！！！")]),t._v(" "),n("p",[n("strong",[t._v("做法")]),t._v("：将查询条件拼到rowkey内")])])}),[],!1,null,null,null);s.default=e.exports}}]);