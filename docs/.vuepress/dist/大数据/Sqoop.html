<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Sqoop | PYY在线笔记文档</title>
    <meta name="description" content="PYY在线笔记文档">
    <meta name="generator" content="VuePress 1.3.1">
    <link rel="icon" href="/study/img/logo.png">
    
    <link rel="preload" href="/study/assets/css/0.styles.adf990bf.css" as="style"><link rel="preload" href="/study/assets/js/app.c33ac112.js" as="script"><link rel="preload" href="/study/assets/js/2.b06d8276.js" as="script"><link rel="preload" href="/study/assets/js/14.2c5fad55.js" as="script"><link rel="prefetch" href="/study/assets/js/10.3abf00ab.js"><link rel="prefetch" href="/study/assets/js/11.124a5830.js"><link rel="prefetch" href="/study/assets/js/12.a6dbc9f4.js"><link rel="prefetch" href="/study/assets/js/13.3488c55a.js"><link rel="prefetch" href="/study/assets/js/15.0e16de52.js"><link rel="prefetch" href="/study/assets/js/16.ea3aa628.js"><link rel="prefetch" href="/study/assets/js/17.a52f7f77.js"><link rel="prefetch" href="/study/assets/js/18.712a4267.js"><link rel="prefetch" href="/study/assets/js/19.cb3d7a75.js"><link rel="prefetch" href="/study/assets/js/20.f23f0f75.js"><link rel="prefetch" href="/study/assets/js/21.46933db6.js"><link rel="prefetch" href="/study/assets/js/22.f023f8fe.js"><link rel="prefetch" href="/study/assets/js/23.29202546.js"><link rel="prefetch" href="/study/assets/js/3.e2416842.js"><link rel="prefetch" href="/study/assets/js/4.05814e74.js"><link rel="prefetch" href="/study/assets/js/5.993850d5.js"><link rel="prefetch" href="/study/assets/js/6.31f1919a.js"><link rel="prefetch" href="/study/assets/js/7.015c571c.js"><link rel="prefetch" href="/study/assets/js/8.f7ed0eb3.js"><link rel="prefetch" href="/study/assets/js/9.791109aa.js">
    <link rel="stylesheet" href="/study/assets/css/0.styles.adf990bf.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/study/" class="home-link router-link-active"><img src="/study/img/logo.png" alt="PYY在线笔记文档" class="logo"> <span class="site-name can-hide">PYY在线笔记文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/study/大数据/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/study/DevOps/" class="nav-link">
  DevOps
</a></div><div class="nav-item"><a href="https://www.jianshu.com/u/af08f637aff8" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://github.com/pyy-admin-x" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/study/大数据/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/study/DevOps/" class="nav-link">
  DevOps
</a></div><div class="nav-item"><a href="https://www.jianshu.com/u/af08f637aff8" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://github.com/pyy-admin-x" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Dev Ops</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>大数据</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/study/大数据/Hadoop.html" class="sidebar-link">Hadoop</a></li><li><a href="/study/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="sidebar-link">介绍</a></li><li><a href="/study/大数据/Azkaban.html" class="sidebar-link">Azkaban</a></li><li><a href="/study/大数据/ElasticSearch.html" class="sidebar-link">ElasticSearch</a></li><li><a href="/study/大数据/Flume.html" class="sidebar-link">Flume</a></li><li><a href="/study/大数据/HBase.html" class="sidebar-link">HBase</a></li><li><a href="/study/大数据/Hive.html" class="sidebar-link">Hive</a></li><li><a href="/study/大数据/Hue.html" class="sidebar-link">Hue</a></li><li><a href="/study/大数据/Kafka.html" class="sidebar-link">Kafka</a></li><li><a href="/study/大数据/Oozie.html" class="sidebar-link">Oozie</a></li><li><a href="/study/大数据/Sqoop.html" class="active sidebar-link">Sqoop</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_1-概述" class="sidebar-link">1. 概述</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_2-sqoop1-与-sqoop2-架构对比" class="sidebar-link">2. Sqoop1 与 Sqoop2 架构对比</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_3-工作机制" class="sidebar-link">3. 工作机制</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_4-sqoop-实战及原理" class="sidebar-link">4. Sqoop 实战及原理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_4-1-sqoop安装" class="sidebar-link">4.1 sqoop安装</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-sqoop-的数据导入" class="sidebar-link">5.  Sqoop 的数据导入</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-1-列举出所有的数据库" class="sidebar-link">5.1 列举出所有的数据库</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-2-查看某一个数据库下面的所有数据表" class="sidebar-link">5.2 查看某一个数据库下面的所有数据表</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-3-导入数据库表数据到-hdfs" class="sidebar-link">5.3 导入数据库表数据到 HDFS</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-4-导入到-hdfs-指定目录" class="sidebar-link">5.4 导入到 HDFS 指定目录</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-5-导入到-hdfs-指定目录并指定字段之间的分隔符" class="sidebar-link">5.5 导入到 HDFS 指定目录并指定字段之间的分隔符</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-6-导入关系表到-hive" class="sidebar-link">5.6 导入关系表到 HIVE</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-7-导入关系表到-hive-并自动创建-hive-表" class="sidebar-link">5.7 导入关系表到 Hive 并自动创建 Hive 表</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-8-导入表数据子集" class="sidebar-link">5.8 导入表数据子集</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-9-sql-语句查找导入-hdfs" class="sidebar-link">5.9 SQL 语句查找导入 HDFS</a></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_5-10-增量导入" class="sidebar-link">5.10 增量导入</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_6-sqoop-的数据导出" class="sidebar-link">6. Sqoop 的数据导出</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/大数据/Sqoop.html#_6-1-hdfs-导出到-mysql" class="sidebar-link">6.1 HDFS 导出到 MySQL</a></li></ul></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="sqoop"><a href="#sqoop" class="header-anchor">#</a> Sqoop</h1> <p>官网地址： <a href="https://links.jianshu.com/go?to=http%3A%2F%2Fsqoop.apache.org%2F" target="_blank" rel="noopener noreferrer">http://sqoop.apache.org/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="data:image/png;base64,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" alt=""></p> <h2 id="_1-概述"><a href="#_1-概述" class="header-anchor">#</a> 1. 概述</h2> <p>sqoop是apache旗下一款“Hadoop和关系数据库服务器之间传送数据”的工具。</p> <p>导入数据：MySQL，Oracle导入数据到Hadoop的HDFS、HIVE、HBASE等数据存储系统；</p> <p>导出数据：从Hadoop的文件系统中导出数据到关系数据库mysql等 。</p> <p>Sqoop 的本质还是一个命令行工具，和 HDFS，Hive 相比，并没有什么高深的理论。</p> <ul><li><p>sqoop：</p> <p>工具，本质就是迁移数据， 迁移的方式：就是把sqoop的迁移命令转换成MR程序</p></li> <li><p>hive</p> <p>工具，本质就是执行计算，依赖于HDFS存储数据，把SQL转换成MR程序</p> <p><img src="/study/assets/img/sqoop1.c95adefa.png" alt=""></p></li></ul> <h2 id="_2-sqoop1-与-sqoop2-架构对比"><a href="#_2-sqoop1-与-sqoop2-架构对比" class="header-anchor">#</a> 2. Sqoop1 与 Sqoop2 架构对比</h2> <ul><li><p><strong>版本号对比</strong></p> <p>两代之间是两个完全不同的版本，不兼容
sqoop1：1.4.x</p> <p>sqoop2：1.99.x</p></li> <li><p><strong>sqoop2比sqoop1的改进</strong></p> <p>(1) 引入sqoop server，集中化管理connector等
(2) 多种访问方式：CLI,Web UI，REST API
(3) 引入基于角色 的安全机制</p></li> <li><p><strong>sqoop2和sqoop1的功能性对比</strong></p> <table><thead><tr><th>功能</th> <th>Sqoop 1</th> <th>Sqoop 2</th></tr></thead> <tbody><tr><td>用于所有主要 RDBMS 的连接器</td> <td>支持</td> <td>不支持<br>解决办法： 使用已在以下数据库上执行测试的通用 JDBC 连接器： Microsoft SQL Server 、 PostgreSQL 、 MySQL 和 Oracle 。 <br>此连接器应在任何其它符合 JDBC 要求的数据库上运行。但是，性能可能无法与 Sqoop 中的专用连接器相比</td></tr> <tr><td>Kerberos 安全集成</td> <td>支持</td> <td>不支持</td></tr> <tr><td>数据从 RDBMS 传输至 Hive 或 HBase</td> <td>支持</td> <td>不支持<br>解决办法： 按照此两步方法操作。 将数据从 RDBMS 导入 HDFS 在 Hive 中使用相应的工具和命令（例如 LOAD DATA 语句），手动将数据载入 Hive 或 HBase</td></tr> <tr><td>数据从 Hive 或 HBase 传输至 RDBMS</td> <td>不支持<br>解决办法： 按照此两步方法操作。 从 Hive 或 HBase 将数据提取至 HDFS （作为文本或 Avro 文件） 使用 Sqoop 将上一步的输出导出至 RDBMS</td> <td>不支持<br>按照与 Sqoop 1 相同的解决方法操作</td></tr></tbody></table></li> <li><p><strong>sqoop1和sqoop2的架构对比</strong></p> <p>sqoop1的架构图</p> <p><img src="/study/assets/img/sqoop1.3f5f8231.jpg" alt=""></p> <p>版本号为1.4.x为sqoop1
在架构上：sqoop1使用sqoop客户端直接提交的方式
访问方式：CLI控制台方式进行访问
安全性：命令或脚本中指定用户数据库名及密码</p> <p>sqoop2的架构图</p> <p><img src="/study/assets/img/sqoop2.51aebe6d.jpg" alt=""></p> <p>版本号为1.99x为sqoop2
在架构上：sqoop2引入了sqoop server，对connector实现了集中的管理
访问方式：REST API、 JAVA API、 WEB UI以及CLI控制台方式进行访问</p> <p>CLI方式访问，会通过交互过程界面，输入的密码信息丌被看到，同时Sqoop2引入基亍角色的安全机制，Sqoop2比Sqoop多了一个Server端。</p></li> <li><p><strong>sqoop1与sqoop2优缺点比较</strong></p> <ul><li><p>sqoop1优点架构部署简单
sqoop1的缺点命令行方式容易出错，格式紧耦合，无法支持所有数据类型，安全机制不够完善，例如密码暴漏，安装需要root权限，connector必须符合JDBC模型</p></li> <li><p>sqoop2的优点多种交互方式，命令行，web UI，rest API，conncetor集中化管理，所有的链接安装在sqoop server上，完善权限管理机制，connector规范化，仅仅负责数据的读写。</p></li> <li><p>sqoop2的缺点，架构稍复杂，配置部署更繁琐。</p></li></ul></li></ul> <h2 id="_3-工作机制"><a href="#_3-工作机制" class="header-anchor">#</a> 3. 工作机制</h2> <p>将导入或导出命令翻译成mapreduce程序来实现</p> <p>在翻译出的mapreduce中主要是对inputformat和outputformat进行定制</p> <h2 id="_4-sqoop-实战及原理"><a href="#_4-sqoop-实战及原理" class="header-anchor">#</a> 4. Sqoop 实战及原理</h2> <h3 id="_4-1-sqoop安装"><a href="#_4-1-sqoop安装" class="header-anchor">#</a> 4.1 <strong>sqoop</strong>安装</h3> <p>安装sqoop的前提是已经具备java和hadoop的环境</p> <p>具体安装不是和安装方式可以自行选择，我们这里采用CDH安装。</p> <p><img src="/study/assets/img/cdh_sqoop.ebc8a2ae.png" alt=""></p> <p>验证启动</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token punctuation">[</span>root@thtf-02 java<span class="token punctuation">]</span><span class="token comment"># sqoop version</span>
Warning: /opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/bin/<span class="token punctuation">..</span>/lib/sqoop/<span class="token punctuation">..</span>/accumulo does not exist<span class="token operator">!</span> Accumulo imports will fail.
Please <span class="token builtin class-name">set</span> <span class="token variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.
<span class="token number">20</span>/03/29 <span class="token number">18</span>:17:46 INFO sqoop.Sqoop: Running Sqoop version: <span class="token number">1.4</span>.6-cdh5.16.1
Sqoop <span class="token number">1.4</span>.6-cdh5.16.1
<span class="token function">git</span> commit <span class="token function">id</span> 
Compiled by jenkins on Wed Nov <span class="token number">21</span> <span class="token number">21</span>:32:45 PST <span class="token number">2018</span>
</code></pre></div><h2 id="_5-sqoop-的数据导入"><a href="#_5-sqoop-的数据导入" class="header-anchor">#</a> 5.  Sqoop 的数据导入</h2> <p>“导入工具”导入单个表从RDBMS到HDFS。表中的每一行被视为HDFS的记录。所有记录都存储为文本文件的文本数据（或者Avro、sequence文件等二进制数据）</p> <h3 id="_5-1-列举出所有的数据库"><a href="#_5-1-列举出所有的数据库" class="header-anchor">#</a> 5.1 列举出所有的数据库</h3> <p>命令行查看帮助</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop list‐databases ‐‐help </span>
</code></pre></div><p>列出指定主机所有的数据库</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop list‐databases ‐‐connect jdbc:mysql://192.168.1.7:3306/ ‐‐ username root ‐‐password 123456</span>
</code></pre></div><h3 id="_5-2-查看某一个数据库下面的所有数据表"><a href="#_5-2-查看某一个数据库下面的所有数据表" class="header-anchor">#</a> 5.2 查看某一个数据库下面的所有数据表</h3> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop list‐tables ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456</span>
</code></pre></div><p>如果出现连接拒绝，则在目标的mysql的数据库中执行以下命令:</p> <p>开启windows的远程连接权限</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">PRIVILEGES</span> <span class="token keyword">ON</span> <span class="token punctuation">.</span> <span class="token keyword">TO</span> <span class="token string">'root'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'yourpassword'</span> <span class="token keyword">WITH</span> <span class="token keyword">GRANT</span> <span class="token keyword">OPTION</span><span class="token punctuation">;</span> 
mysql<span class="token operator">&gt;</span> FLUSH <span class="token keyword">PRIVILEGES</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="_5-3-导入数据库表数据到-hdfs"><a href="#_5-3-导入数据库表数据到-hdfs" class="header-anchor">#</a> 5.3 导入数据库表数据到 HDFS</h3> <p>下面的命令用于从MySQL数据库服务器中的emp表导入HDFS</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐username root ‐‐ password 123456 ‐‐table emp ‐‐m 1</span>
</code></pre></div><blockquote><p>注：--m :  指定maptask个数</p></blockquote> <h3 id="_5-4-导入到-hdfs-指定目录"><a href="#_5-4-导入到-hdfs-指定目录" class="header-anchor">#</a> 5.4 导入到 HDFS 指定目录</h3> <p>在导入表数据到HDFS使用Sqoop导入工具，我们可以指定目标目录。</p> <p>使用参数 --target-dir来指定导出目的地，</p> <p>使用参数—delete-target-dir来判断导出目录是否存在，如果存在就删掉</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment"># sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐delete‐target‐dir ‐‐table emp ‐‐target‐dir /sqoop/emp ‐‐m 1</span>
</code></pre></div><p>默认，它会用逗号（，）分隔emp_add表的数据和字段。</p> <div class="language- extra-class"><pre class="language-text"><code>1201,gopal,manager,50000,TP 
1202,manisha,Proof reader,50000,TP 
1203,khalil,php dev,30000,AC 
1204,prasanth,php dev,30000,AC 
1205,kranthi,admin,20000,TP
</code></pre></div><h3 id="_5-5-导入到-hdfs-指定目录并指定字段之间的分隔符"><a href="#_5-5-导入到-hdfs-指定目录并指定字段之间的分隔符" class="header-anchor">#</a> 5.5 导入到 HDFS 指定目录并指定字段之间的分隔符</h3> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐delete‐target‐dir ‐‐table emp ‐‐target‐dir /sqoop/emp2 ‐‐m 1 ‐‐fields‐terminated‐by '\t'</span>
</code></pre></div><h3 id="_5-6-导入关系表到-hive"><a href="#_5-6-导入关系表到-hive" class="header-anchor">#</a> 5.6 导入关系表到 HIVE</h3> <ul><li><p>第一步：拷贝<strong>jar</strong>包（如果是使用CDH安装则不需要此步骤）</p> <p>将我们mysql表当中的数据直接导入到hive表中的话，我们需要将hive的一个叫做hive-exec-3.1.1.jar 的jar包拷贝到sqoop的lib目录下</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#cp /export/servers/apache‐hive‐3.1.1‐bin/lib/hive‐exec‐3.1.1.jar /export/servers/sqoop‐1.4.7.bin__hadoop‐2.6.0/lib</span>
</code></pre></div></li> <li><p>第二步：准备<strong>hive</strong>数据库与表</p> <div class="language-sql extra-class"><pre class="language-sql"><code>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token keyword">database</span> sqooptohive<span class="token punctuation">;</span> hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">use</span> sqooptohive<span class="token punctuation">;</span> hive <span class="token punctuation">(</span>sqooptohive<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">create</span> external <span class="token keyword">table</span> emp_hive<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">,</span>deg string<span class="token punctuation">,</span>salary <span class="token keyword">int</span> <span class="token punctuation">,</span>dept string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\001'</span><span class="token punctuation">;</span>
</code></pre></div></li> <li><p>第三步：开始导入</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐table emp ‐‐fields‐terminated‐by '\001' ‐ ‐hive‐import ‐‐hive‐table sqooptohive.emp_hive ‐‐hive‐overwrite ‐‐delete‐ target‐dir ‐‐m 1</span>
</code></pre></div></li> <li><p>第四步：<strong>hive</strong>表数据查看</p> <div class="language-sql extra-class"><pre class="language-sql"><code>hive<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp_hive<span class="token punctuation">;</span>
OK
<span class="token number">1201</span>    gopal   manager <span class="token number">50</span><span class="token punctuation">,</span><span class="token number">000</span>  tp
<span class="token number">1202</span>    manisha Proof reader    <span class="token number">50</span><span class="token punctuation">,</span><span class="token number">000</span>  tp
<span class="token number">1203</span>    khalil  java dev        <span class="token number">30</span><span class="token punctuation">,</span><span class="token number">000</span>  tp
<span class="token number">1204</span>    prasanth        java dev        <span class="token number">50</span><span class="token punctuation">,</span><span class="token number">000</span>  tp
<span class="token number">1205</span>    kranthi java dev        <span class="token number">50</span><span class="token punctuation">,</span><span class="token number">000</span>  tp
<span class="token keyword">Time</span> taken: <span class="token number">0.711</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">5</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre></div></li></ul> <h3 id="_5-7-导入关系表到-hive-并自动创建-hive-表"><a href="#_5-7-导入关系表到-hive-并自动创建-hive-表" class="header-anchor">#</a> 5.7 导入关系表到 Hive 并自动创建 Hive 表</h3> <p>我们也可以通过命令来将我们的mysql的表直接导入到hive表当中去</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import ‐‐connect jdbc:mysql://192.168.1.7:3306/userdb ‐‐ username root ‐‐password 123456 ‐‐table emp_conn ‐‐hive‐import ‐m 1 ‐‐hive‐database sqooptohive</span>
</code></pre></div><p>通过这个命令，我们可以直接将我们mysql表当中的数据以及表结构一起倒入到hive当中去</p> <h3 id="_5-8-导入表数据子集"><a href="#_5-8-导入表数据子集" class="header-anchor">#</a> 5.8 导入表数据子集</h3> <p>我们可以导入表的使用Sqoop导入工具，&quot;where&quot;子句的一个子集。它执行在各自的数据</p> <p>库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。</p> <p>where子句的语法如下：</p> <p>​	按照条件进行查找，通过—where参数来查找表emp_add当中city字段的值为sec-bad的所有数据导入到hdfs上	面去</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import \ </span>
‐‐connect jdbc:mysql://192.168.1.7:3306/userdb <span class="token punctuation">\</span> 
‐‐username root ‐‐password <span class="token number">123456</span> ‐‐table emp_add <span class="token punctuation">\</span> 
‐‐target‐dir /sqoop/emp_add ‐m <span class="token number">1</span> ‐‐delete‐target‐dir <span class="token punctuation">\</span> 
‐‐where <span class="token string">&quot;city = 'sec‐bad'&quot;</span>
</code></pre></div><h3 id="_5-9-sql-语句查找导入-hdfs"><a href="#_5-9-sql-语句查找导入-hdfs" class="header-anchor">#</a> 5.9 SQL 语句查找导入 HDFS</h3> <p>我们还可以通过 –query参数来指定我们的sql语句，通过sql语句来过滤我们的数据进行导入</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import \ </span>
‐‐connect jdbc:mysql://192.168.1.7:3306/userdb <span class="token punctuation">\</span>
‐‐username root ‐‐password <span class="token number">123456</span><span class="token punctuation">\</span> 
‐‐delete‐target‐dir ‐m <span class="token number">1</span> <span class="token punctuation">\</span> 
‐‐query <span class="token string">'select email from emp_conn where 1=1 and <span class="token variable">$CONDITIONS</span>'</span> <span class="token punctuation">\</span> 
‐‐target‐dir /sqoop/emp_conn
</code></pre></div><h3 id="_5-10-增量导入"><a href="#_5-10-增量导入" class="header-anchor">#</a> 5.10 增量导入</h3> <p>在实际工作当中，数据的导入，很多时候都是只需要导入增量数据即可，并不需要将表中的数据全部导入到hive或者hdfs当中去，肯定会出现重复的数据的状况，所以我们一般都是选用一些字段进行增量的导入，为了支持增量的导入，sqoop也给我们考虑到了这种情况并且支持增量的导入数据</p> <p>增量导入是仅导入新添加的表中的行的技术。</p> <p>它需要添加‘incremental’, ‘check-column’, 和 ‘last-value’选项来执行增量导入。</p> <p>下面的语法用于Sqoop导入命令增量选项。</p> <p>**第一种增量导入使用上面的选项来实现 **</p> <p>导入emp表当中id大于1202的所有数据</p> <blockquote><p>注意：增量导入的时候，一定不能加参数--delete-target-dir否则会报错</p></blockquote> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop import \ </span>
‐‐connect jdbc:mysql://192.168.1.7:3306/userdb <span class="token punctuation">\</span> 
‐‐username root <span class="token punctuation">\</span> 
‐‐password <span class="token number">123456</span> <span class="token punctuation">\</span> 
‐‐table emp <span class="token punctuation">\</span> 
‐‐incremental append <span class="token punctuation">\</span> 
‐‐check‐column <span class="token function">id</span> <span class="token punctuation">\</span> 
‐‐last‐value <span class="token number">1202</span> <span class="token punctuation">\</span> 
‐m <span class="token number">1</span> <span class="token punctuation">\</span> 
‐‐target‐dir /sqoop/increment
</code></pre></div><p><strong>第二种增量导入通过</strong>--where**条件来实现 **</p> <p>或者我们使用--where来进行控制数据的选取会更加精准</p> <div class="language- extra-class"><pre class="language-text"><code>#sqoop import \ 
‐‐connect jdbc:mysql://192.168.1.7:3306/userdb \ 
‐‐username root \ 
‐‐password 123456 \ 
‐‐table emp \ 
‐‐incremental append \ 
‐‐where &quot;create_time &gt; '2018‐06‐17 00:00:00' and create_time &lt; '2018‐06‐ 17 23:59:59'&quot; \
‐‐target‐dir /sqoop/incement2 \ 
‐‐check‐column id \ 
‐‐m 1
</code></pre></div><h2 id="_6-sqoop-的数据导出"><a href="#_6-sqoop-的数据导出" class="header-anchor">#</a> 6. Sqoop 的数据导出</h2> <ol><li><p>将数据从HDFS把文件导出到RDBMS数据库</p> <p>导出前，目标表必须存在于目标数据库中。</p> <ul><li><p>默认操作是从将文件中的数据使用INSERT语句插入到表中</p></li> <li><p>更新模式下，是生成UPDATE语句更新表数据</p></li></ul></li></ol> <h3 id="_6-1-hdfs-导出到-mysql"><a href="#_6-1-hdfs-导出到-mysql" class="header-anchor">#</a> 6.1 HDFS 导出到 MySQL</h3> <p>数据是在HDFS当中的如下目录/sqoop/emp，数据内容如下</p> <div class="language-xml extra-class"><pre class="language-xml"><code>1201,gopal,manager,50000,TP,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1
1202,manisha,Proof reader,50000,TP,2018-06-15 18:54:32.0,2018-06-17 20:26:08.0,1 
1203,khalil,php dev,30000,AC,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1 
1204,prasanth,php dev,30000,AC,2018-06-17 18:54:32.0,2018-06-17 21:05:52.0,0 
1205,kranthi,admin,20000,TP,2018-06-17 18:54:32.0,2018-06-17 18:54:32.0,1
</code></pre></div><p>第一步：创建<strong>mysql</strong>表</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> emp_out <span class="token punctuation">(</span> 
    id <span class="token keyword">INT</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> 
    name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> 
    deg <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> 
    salary <span class="token keyword">INT</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> 
    dept <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> 
    create_time <span class="token keyword">TIMESTAMP</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CURRENT_TIMESTAMP</span><span class="token punctuation">,</span> 
    update_time <span class="token keyword">TIMESTAMP</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">ON</span> <span class="token keyword">UPDATE</span> <span class="token keyword">CURRENT_TIMESTAMP</span><span class="token punctuation">,</span>
    is_delete <span class="token keyword">BIGINT</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token string">'1'</span> <span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">INNODB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span>
</code></pre></div><p>第二步：执行导出命令</p> <p>通过export来实现数据的导出，将hdfs的数据导出到mysql当中去</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#sqoop export \ </span>
‐‐connect jdbc:mysql://192.168.1.7:3306/userdb <span class="token punctuation">\</span> 
‐‐username root ‐‐password <span class="token number">123456</span> <span class="token punctuation">\</span> 
‐‐table emp_out <span class="token punctuation">\</span> 
‐‐export‐dir /sqoop/emp <span class="token punctuation">\</span> 
‐‐input‐fields‐terminated‐by <span class="token string">&quot;,&quot;</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/study/大数据/Oozie.html" class="prev">
        Oozie
      </a></span> <!----></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/study/assets/js/app.c33ac112.js" defer></script><script src="/study/assets/js/2.b06d8276.js" defer></script><script src="/study/assets/js/14.2c5fad55.js" defer></script>
  </body>
</html>
